{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/andreea/Desktop/licenta/plots_keras\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from AMRGraph import AMR\n",
    "from AMRData import CustomizedAMR\n",
    "from utilities import pretty_print, generate_action_sequence, generate_custom_amr\n",
    "import preprocessing.ActionSequenceGenerator as asc\n",
    "from preprocessing.DependencyExtractor import extract_dependencies\n",
    "from preprocessing import TokensReplacer\n",
    "from keras_lstm_flow import test_without_amr\n",
    "from postprocessing import ActionSequenceReconstruction as asr\n",
    "import TestDataExtractor\n",
    "import preprocessing.NamedEntitiesReplacer as ner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentence = \"During a time of prosperity and happiness , such a big earthquake suddenly struck\"\n",
    "amr = \"\"\"(s / strike-01~e.13 \n",
    "      :ARG2 (e / earthquake~e.11 \n",
    "            :mod (b / big~e.10 \n",
    "                  :mod (s2 / such~e.8))) \n",
    "      :time~e.0,2 (t / time~e.2 \n",
    "            :op1~e.3 (p / prosper-01~e.4) \n",
    "            :op2 (h / happiness~e.6)) \n",
    "      :manner~e.12 (s3 / sudden~e.12))\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  We transform the input into a custom structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mappings between node variables and their corresponding concepts.\n",
      "\n",
      "{'b': 'big', 'e': 'earthquake', 's3': 'sudden', 'h': 'happiness', 'p': 'prosper-01', 's': 'strike-01', 't': 'time', 's2': 'such'}\n",
      "\n",
      "Mappings between nodes and all the aligned tokens: If the nodes don't havea variable (polarity, literals, quantities, interrogatives), they specify both the aligned tokens and the parent in order to uniquely identify them\n",
      "\n",
      "{'b': ['10'], 'e': ['11'], 's3': ['12'], 'h': ['6'], 'p': ['4'], 's': ['13'], 't': ['2'], 's2': ['8']}\n",
      "\n",
      "Mappings between relations and tokens. Uniquely identified by also specifying the parent of that relation.\n",
      "\n",
      "{'manner': [[('12', 's')]], 'op1': [[('3', 't')]], 'time': [[('0', 's')], ('2', 's')]}\n",
      "\n",
      "Mappings from a node to each child, along with the relation between them.\n",
      "\n",
      "Key: b\n",
      "mod -> s2\n",
      "\n",
      "Key: e\n",
      "mod -> b\n",
      "\n",
      "Key: s3\n",
      "Leaf\n",
      "\n",
      "Key: h\n",
      "Leaf\n",
      "\n",
      "Key: p\n",
      "Leaf\n",
      "\n",
      "Key: s\n",
      "ARG2 -> e\n",
      "manner -> s3\n",
      "time -> t\n",
      "\n",
      "Key: t\n",
      "op1 -> p\n",
      "op2 -> h\n",
      "\n",
      "Key: s2\n",
      "Leaf\n",
      "\n",
      "\n",
      "All the nodes in the amr should appear here.\n",
      "\n",
      "['b', 'e', 's3', 'h', 'p', 's', 't', 's2']\n",
      "\n",
      "Creating custom AMR.\n",
      "\n",
      "\n",
      "Custom AMR token to concepts dict\n",
      "\n",
      "{2: ('t', 'time'), 4: ('p', 'prosper-01'), 6: ('h', 'happiness'), 8: ('s2', 'such'), 10: ('b', 'big'), 11: ('e', 'earthquake'), 12: ('s3', 'sudden'), 13: ('s', 'strike-01')}\n",
      "\n",
      "Custom AMR relations dict\n",
      "\n",
      "{('s', ''): ('', ['e', 's3', 't'], ['13']), ('e', 's'): ('ARG2', ['b'], ['11']), ('s2', 'b'): ('mod', [], ['8']), ('p', 't'): ('op1', [], ['4']), ('s3', 's'): ('manner', [], ['12']), ('h', 't'): ('op2', [], ['6']), ('t', 's'): ('time', ['p', 'h'], ['2']), ('b', 'e'): ('mod', ['s2'], ['10'])}\n",
      "\n",
      "Custom AMR parent dict\n",
      "\n",
      "{'b': 'e', 'e': 's', 's3': 's', 's2': 'b', 'p': 't', 's': '', 't': 's', 'h': 't'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AMRData.CustomizedAMR instance at 0x7f1dec0e8440>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amrStruct = AMR.parse_string(amr)\n",
    "generate_custom_amr(amrStruct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we take an example which contains 2 named entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mappings between node variables and their corresponding concepts.\n",
      "\n",
      "{'a': 'and', 'c': 'company', 'b': 'bus', 'd': 'deploy-01', 't2': 'travel-01', 't3': 'this', 'o': 'order-02', 'n': 'name', 'a3': 'all', 'a2': 'accept-01', 't': 'thing', 'w': 'we', 'c2': 'city', 'n2': 'name', 'o2': 'other', 'a4': 'agency'}\n",
      "\n",
      "Mappings between nodes and all the aligned tokens: If the nodes don't havea variable (polarity, literals, quantities, interrogatives), they specify both the aligned tokens and the parent in order to uniquely identify them\n",
      "\n",
      "{'a': ['6'], 'b': ['10'], 'd': ['7'], u'Xinghui': [(u'0', 'n2')], 't2': ['13'], 't3': ['2'], 'o': ['3'], 'w': ['5'], 'a3': ['8'], 'a2': ['1'], 't': ['3'], u'Sydney': [(u'16', 'n')], 'o2': ['12'], 'a4': ['14']}\n",
      "\n",
      "Mappings between relations and tokens. Uniquely identified by also specifying the parent of that relation.\n",
      "\n",
      "{'ARG0': [[('4', 'o')]], 'ARG1-of': [[('3', 't')]], 'location': [[('15', 'a4')]], 'poss': [[('11', 'b')]]}\n",
      "\n",
      "Mappings from a node to each child, along with the relation between them.\n",
      "\n",
      "Key: Sydney\n",
      "Leaf\n",
      "\n",
      "Key: -\n",
      "Leaf\n",
      "\n",
      "Key: o2\n",
      "Leaf\n",
      "\n",
      "Key: Xinghui\n",
      "Leaf\n",
      "\n",
      "Key: a3\n",
      "Leaf\n",
      "\n",
      "Key: a2\n",
      "ARG0 -> c\n",
      "ARG1 -> t\n",
      "\n",
      "Key: a4\n",
      "location -> c2\n",
      "mod -> t2\n",
      "\n",
      "Key: c2\n",
      "wiki -> Sydney\n",
      "name -> n\n",
      "\n",
      "Key: a\n",
      "op1 -> a2\n",
      "op2 -> d\n",
      "\n",
      "Key: c\n",
      "wiki -> -\n",
      "name -> n2\n",
      "\n",
      "Key: b\n",
      "poss -> a4\n",
      "mod -> a3\n",
      "\n",
      "Key: d\n",
      "ARG0 -> c\n",
      "ARG1 -> b\n",
      "\n",
      "Key: t2\n",
      "Leaf\n",
      "\n",
      "Key: t3\n",
      "Leaf\n",
      "\n",
      "Key: o\n",
      "ARG0 -> w\n",
      "\n",
      "Key: n\n",
      "op1 -> Sydney\n",
      "\n",
      "Key: t\n",
      "ARG1-of -> o\n",
      "mod -> t3\n",
      "\n",
      "Key: w\n",
      "Leaf\n",
      "\n",
      "Key: n2\n",
      "op1 -> Xinghui\n",
      "\n",
      "\n",
      "All the nodes in the amr should appear here.\n",
      "\n",
      "[u'Sydney', '-', 'o2', u'Xinghui', 'a3', 'a2', 'a4', 'c2', 'a', 'c', 'b', 'd', 't2', 't3', 'o', 'n', 't', 'w', 'n2']\n",
      "\n",
      "Creating custom AMR.\n",
      "\n",
      "\n",
      "Custom AMR token to concepts dict\n",
      "\n",
      "{1: ('a2', 'accept-01'), 2: ('t3', 'this'), 3: ('t', 'thing'), 5: ('w', 'we'), 6: ('a', 'and'), 7: ('d', 'deploy-01'), 8: ('a3', 'all'), 10: ('b', 'bus'), 12: ('o2', 'other'), 13: ('t2', 'travel-01'), 14: ('a4', 'agency')}\n",
      "\n",
      "Custom AMR relations dict\n",
      "\n",
      "{('a4', 'b'): ('poss', ['c2', 't2'], ['14']), ('a3', 'b'): ('mod', [], ['8']), ('t3', 't'): ('mod', [], ['2']), ('b', 'd'): ('ARG1', ['a4', 'a3'], ['10']), (u'Xinghui', 'n2'): ('op1', [], [u'0']), (u'Sydney', 'c2'): ('wiki', [], ''), ('a', ''): ('', ['a2', 'd'], ['6']), (u'Sydney', 'n'): ('op1', [], [u'16']), ('w', 'o'): ('ARG0', [], ['5']), ('o', 't'): ('ARG1-of', ['w'], ['3']), ('a2', 'a'): ('op1', ['c', 't'], ['1']), ('c', 'a2'): ('ARG0', ['-', 'n2'], ''), ('n2', 'c'): ('name', [u'Xinghui'], ''), ('c2', 'a4'): ('location', [u'Sydney', 'n'], ''), ('c', 'd'): ('ARG0', [], ''), ('t', 'a2'): ('ARG1', ['o', 't3'], ['3']), ('t2', 'a4'): ('mod', [], ['13']), ('-', 'c'): ('wiki', [], ''), ('n', 'c2'): ('name', [u'Sydney'], ''), ('d', 'a'): ('op2', ['c', 'b'], ['7'])}\n",
      "\n",
      "Custom AMR parent dict\n",
      "\n",
      "{'a': '', 'c': 'd', 'b': 'd', 'd': 'a', '-': 'c', 't2': 'a4', 't3': 't', 'o': 't', 'n': 'c2', 'w': 'o', 'a3': 'b', 'a2': 'a', 't': 'a2', u'Sydney': 'n', u'Xinghui': 'n2', 'c2': 'a4', 'n2': 'c', 'a4': 'b'}\n"
     ]
    }
   ],
   "source": [
    "sentence = \"Xinghui accepted this order of ours and deployed all the buses of other travel agencies in Sydney .\"\n",
    "amr = \"\"\"(a / and~e.6 \n",
    "      :op1 (a2 / accept-01~e.1 \n",
    "            :ARG0 (c / company :wiki - \n",
    "                  :name (n2 / name :op1 \"Xinghui\"~e.0)) \n",
    "            :ARG1 (t / thing~e.3 \n",
    "                  :ARG1-of~e.3 (o / order-02~e.3 \n",
    "                        :ARG0~e.4 (w / we~e.5)) \n",
    "                  :mod (t3 / this~e.2))) \n",
    "      :op2 (d / deploy-01~e.7 \n",
    "            :ARG0 c \n",
    "            :ARG1 (b / bus~e.10 \n",
    "                  :mod (a3 / all~e.8) \n",
    "                  :poss~e.11 (a4 / agency~e.14 \n",
    "                        :mod (t2 / travel-01~e.13) \n",
    "                        :mod (o2 / other~e.12) \n",
    "                        :location~e.15 (c2 / city :wiki \"Sydney\" \n",
    "                              :name (n / name :op1 \"Sydney\"~e.16))))))\"\"\"\n",
    "amrStruct = AMR.parse_string(amr)\n",
    "customAMR = generate_custom_amr(amrStruct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We preprocess the sentence by using NER parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'Xinghui', u'PERSON'), (u'accepted', u'O'), (u'this', u'O'), (u'order', u'O'), (u'of', u'O'), (u'ours', u'O'), (u'and', u'O'), (u'deployed', u'O'), (u'all', u'O'), (u'the', u'O'), (u'buses', u'O'), (u'of', u'O'), (u'other', u'O'), (u'travel', u'O'), (u'agencies', u'O'), (u'in', u'O'), (u'Sydney', u'LOCATION'), (u'.', u'O')]\n",
      "[u'PERSON', u'accepted', u'this', u'order', u'of', u'ours', u'and', u'deployed', u'all', u'the', u'buses', u'of', u'other', u'travel', u'agencies', u'in', u'LOCATION', u'.']\n",
      "PERSON accepted this order of ours and deployed all the buses of other travel agencies in LOCATION . \n",
      "[(0, [u'Xinghui']), (16, [u'Sydney'])]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(u'PERSON accepted this order of ours and deployed all the buses of other travel agencies in LOCATION . ',\n",
       " [(0, [u'Xinghui']), (16, [u'Sydney'])])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner.process_sentence(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We preprocess the same sentence by using NLTK and observe that only one of the entities is found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sydney']\n"
     ]
    }
   ],
   "source": [
    "ner.process_language([sentence]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we are going to present the entire flow of predicting the AMR structure, without using any information from the existing AMR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model1 = \"all_epochs=20_maxlen=30_embeddingsdim=200\"\n",
    "max_len1=30\n",
    "embeddings_dim1=200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"upgrade fire control systems of India tanks .\"\n",
    "\n",
    "amr_str= \"\"\"(u / upgrade-02~e.0 \n",
    "      :ARG1 (s / system~e.3 \n",
    "            :ARG0-of (c / control-01~e.2 \n",
    "                  :ARG1 (f / fire-01~e.1)) \n",
    "            :poss~e.4 (t / tank~e.6 \n",
    "                  :mod (c2 / country :wiki \"India\" \n",
    "                        :name (n / name :op1 \"India\"~e.5)))))\"\"\"\n",
    "amr = AMR.parse_string(amr_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mappings between node variables and their corresponding concepts.\n",
      "\n",
      "{'c': 'control-01', 'f': 'fire-01', 'n': 'name', 's': 'system', 'u': 'upgrade-02', 't': 'tank', 'c2': 'country'}\n",
      "\n",
      "Mappings between nodes and all the aligned tokens: If the nodes don't havea variable (polarity, literals, quantities, interrogatives), they specify both the aligned tokens and the parent in order to uniquely identify them\n",
      "\n",
      "{'c': ['2'], 'f': ['1'], u'India': [(u'5', 'n')], 's': ['3'], 'u': ['0'], 't': ['6']}\n",
      "\n",
      "Mappings between relations and tokens. Uniquely identified by also specifying the parent of that relation.\n",
      "\n",
      "{'poss': [[('4', 's')]]}\n",
      "\n",
      "Mappings from a node to each child, along with the relation between them.\n",
      "\n",
      "Key: c\n",
      "ARG1 -> f\n",
      "\n",
      "Key: f\n",
      "Leaf\n",
      "\n",
      "Key: India\n",
      "Leaf\n",
      "\n",
      "Key: n\n",
      "op1 -> India\n",
      "\n",
      "Key: s\n",
      "ARG0-of -> c\n",
      "poss -> t\n",
      "\n",
      "Key: u\n",
      "ARG1 -> s\n",
      "\n",
      "Key: t\n",
      "mod -> c2\n",
      "\n",
      "Key: c2\n",
      "wiki -> India\n",
      "name -> n\n",
      "\n",
      "\n",
      "All the nodes in the amr should appear here.\n",
      "\n",
      "['c', 'f', u'India', 'n', 's', 'u', 't', 'c2']\n",
      "\n",
      "Creating custom AMR.\n",
      "\n",
      "\n",
      "Custom AMR token to concepts dict\n",
      "\n",
      "{0: ('u', 'upgrade-02'), 1: ('f', 'fire-01'), 2: ('c', 'control-01'), 3: ('s', 'system'), 6: ('t', 'tank')}\n",
      "\n",
      "Custom AMR relations dict\n",
      "\n",
      "{(u'India', 'n'): ('op1', [], [u'5']), ('c', 's'): ('ARG0-of', ['f'], ['2']), (u'India', 'c2'): ('wiki', [], ''), ('n', 'c2'): ('name', [u'India'], ''), ('u', ''): ('', ['s'], ['0']), ('c2', 't'): ('mod', [u'India', 'n'], ''), ('t', 's'): ('poss', ['c2'], ['6']), ('s', 'u'): ('ARG1', ['c', 't'], ['3']), ('f', 'c'): ('ARG1', [], ['1'])}\n",
      "\n",
      "Custom AMR parent dict\n",
      "\n",
      "{'c': 's', 'f': 'c', u'India': 'c2', 'n': 'c2', 's': 'u', 'u': '', 't': 's', 'c2': 't'}\n"
     ]
    }
   ],
   "source": [
    "custom_amr=generate_custom_amr(amr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "deps = extract_dependencies(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'upgrade', u'O'), (u'fire', u'O'), (u'control', u'O'), (u'systems', u'O'), (u'of', u'O'), (u'India', u'LOCATION'), (u'tanks', u'O'), (u'.', u'O')]\n",
      "[u'upgrade', u'fire', u'control', u'systems', u'of', u'LOCATION', u'tanks', u'.']\n",
      "upgrade fire control systems of LOCATION tanks . \n",
      "[(5, [u'India'])]\n"
     ]
    }
   ],
   "source": [
    "(new_sentence, named_entities) = ner.process_sentence(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we will use our pre-trained model in order to predict the AMR structure for the original sentence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_lstm_flow import test_without_amr, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model path is:\n",
      "./models/all_epochs=20_maxlen=30_embeddingsdim=200\n",
      "Word index len: \n",
      "7107\n",
      "Test data shape: \n",
      "(1, 7)\n",
      "1\n",
      "Found 400000 word vectors.\n",
      "Embedding match for volume-quantity\n",
      "Embedding match for distance-quantity\n",
      "Embedding match for energy-quantity\n",
      "Embedding match for power-quantity\n",
      "Embedding match for mass-quantity\n",
      "Embedding match for monetary-quantity\n",
      "Embedding match for temporal-quantity\n",
      "Embedding match for date-entity\n",
      "First 2 not found: [\"don'cha\", 'it...']\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 30)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_2 (InputLayer)             (None, 30)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_3 (InputLayer)             (None, 30)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_4 (InputLayer)             (None, 30)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)          (None, 30, 200)       1421800     input_1[0][0]                    \n",
      "                                                                   input_2[0][0]                    \n",
      "                                                                   input_3[0][0]                    \n",
      "                                                                   input_4[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "input_5 (InputLayer)             (None, 30, 5)         0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_6 (InputLayer)             (None, 30, 6)         0                                            \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)      (None, 30, 811)       0           embedding_1[0][0]                \n",
      "                                                                   embedding_1[1][0]                \n",
      "                                                                   embedding_1[2][0]                \n",
      "                                                                   embedding_1[3][0]                \n",
      "                                                                   input_5[0][0]                    \n",
      "                                                                   input_6[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                    (None, 30, 1024)      7520256     concatenate_1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistribu (None, 30, 5)         5125        lstm_1[0][0]                     \n",
      "====================================================================================================\n",
      "Total params: 8,947,181\n",
      "Trainable params: 7,525,381\n",
      "Non-trainable params: 1,421,800\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 30)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_2 (InputLayer)             (None, 30)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_3 (InputLayer)             (None, 30)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_4 (InputLayer)             (None, 30)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)          (None, 30, 200)       1421800     input_1[0][0]                    \n",
      "                                                                   input_2[0][0]                    \n",
      "                                                                   input_3[0][0]                    \n",
      "                                                                   input_4[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "input_5 (InputLayer)             (None, 30, 5)         0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_6 (InputLayer)             (None, 30, 6)         0                                            \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)      (None, 30, 811)       0           embedding_1[0][0]                \n",
      "                                                                   embedding_1[1][0]                \n",
      "                                                                   embedding_1[2][0]                \n",
      "                                                                   embedding_1[3][0]                \n",
      "                                                                   input_5[0][0]                    \n",
      "                                                                   input_6[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                    (None, 30, 1024)      7520256     concatenate_1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistribu (None, 30, 5)         5125        lstm_1[0][0]                     \n",
      "====================================================================================================\n",
      "Total params: 8,947,181\n",
      "Trainable params: 7,525,381\n",
      "Non-trainable params: 1,421,800\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "Buffer and stack at end of prediction\n",
      "[]\n",
      "[2656]\n",
      "Sentence\n",
      "upgrade fire control systems of tanks . \n",
      "\n",
      "Predicted\n",
      "SH SH SH RL SH RL DN SH RL DN RR \n",
      "\n",
      "AMR skeleton without labels: \n",
      "['SH_unk', 'SH_unk', 'SH_unk', 'RL_unk', 'SH_unk', 'RL_unk', 'DN', 'SH_unk', 'RL_unk', 'DN', 'RR_unk']\n",
      "Predicted Amr\n",
      "( d1 / unk \n",
      "\t:unk  ( d1_1 / unk \n",
      "\t\t:unk  ( d1_1_1 / unk \n",
      "\t\t\t:unk  ( d1_1_1_1 / unk \n",
      "\t\t\t\t:unk  ( d1_1_1_1_1 / unk )\n",
      "\t\t\t)\n",
      "\t\t)\n",
      "\t)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 1, 0, 1, 3, 0, 1, 3, 2]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_without_amr(model_name=model1, tokenizer_path=\"./tokenizers/full_tokenizer.dump\",\n",
    "     data=[(sentence, deps, [])], max_len=max_len1, embedding_dim=embeddings_dim1, with_reattach=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# we now predict the AMR structure for the sentence after the named entity was replaced "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "replaced_sentence = \"upgrade fire control systems of LOCATION tanks\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model path is:\n",
      "./models/all_epochs=20_maxlen=30_embeddingsdim=200\n",
      "Word index len: \n",
      "7107\n",
      "Test data shape: \n",
      "(1, 7)\n",
      "1\n",
      "Found 400000 word vectors.\n",
      "Embedding match for volume-quantity\n",
      "Embedding match for distance-quantity\n",
      "Embedding match for energy-quantity\n",
      "Embedding match for power-quantity\n",
      "Embedding match for mass-quantity\n",
      "Embedding match for monetary-quantity\n",
      "Embedding match for temporal-quantity\n",
      "Embedding match for date-entity\n",
      "First 2 not found: [\"don'cha\", 'it...']\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_13 (InputLayer)            (None, 30)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_14 (InputLayer)            (None, 30)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_15 (InputLayer)            (None, 30)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_16 (InputLayer)            (None, 30)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)          (None, 30, 200)       1421800     input_13[0][0]                   \n",
      "                                                                   input_14[0][0]                   \n",
      "                                                                   input_15[0][0]                   \n",
      "                                                                   input_16[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "input_17 (InputLayer)            (None, 30, 5)         0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_18 (InputLayer)            (None, 30, 6)         0                                            \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)      (None, 30, 811)       0           embedding_3[0][0]                \n",
      "                                                                   embedding_3[1][0]                \n",
      "                                                                   embedding_3[2][0]                \n",
      "                                                                   embedding_3[3][0]                \n",
      "                                                                   input_17[0][0]                   \n",
      "                                                                   input_18[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                    (None, 30, 1024)      7520256     concatenate_3[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "time_distributed_3 (TimeDistribu (None, 30, 5)         5125        lstm_3[0][0]                     \n",
      "====================================================================================================\n",
      "Total params: 8,947,181\n",
      "Trainable params: 7,525,381\n",
      "Non-trainable params: 1,421,800\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_13 (InputLayer)            (None, 30)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_14 (InputLayer)            (None, 30)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_15 (InputLayer)            (None, 30)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_16 (InputLayer)            (None, 30)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)          (None, 30, 200)       1421800     input_13[0][0]                   \n",
      "                                                                   input_14[0][0]                   \n",
      "                                                                   input_15[0][0]                   \n",
      "                                                                   input_16[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "input_17 (InputLayer)            (None, 30, 5)         0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_18 (InputLayer)            (None, 30, 6)         0                                            \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)      (None, 30, 811)       0           embedding_3[0][0]                \n",
      "                                                                   embedding_3[1][0]                \n",
      "                                                                   embedding_3[2][0]                \n",
      "                                                                   embedding_3[3][0]                \n",
      "                                                                   input_17[0][0]                   \n",
      "                                                                   input_18[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                    (None, 30, 1024)      7520256     concatenate_3[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "time_distributed_3 (TimeDistribu (None, 30, 5)         5125        lstm_3[0][0]                     \n",
      "====================================================================================================\n",
      "Total params: 8,947,181\n",
      "Trainable params: 7,525,381\n",
      "Non-trainable params: 1,421,800\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "Buffer and stack at end of prediction\n",
      "[]\n",
      "[2656]\n",
      "Sentence\n",
      "upgrade fire control systems of location tanks \n",
      "\n",
      "Predicted\n",
      "SH SH SH RL SH RL DN SH SH RL RR RR \n",
      "\n",
      "AMR skeleton without labels: \n",
      "['SH_unk', 'SH_unk', 'SH_unk', 'RL_unk', 'SH_unk', 'RL_unk', 'DN', 'SH_unk', 'SH_unk', 'RL_unk', 'RR_unk', 'RR_unk']\n",
      "Predicted Amr\n",
      "( d1 / unk \n",
      "\t:unk  ( d1_1 / unk \n",
      "\t\t:unk  ( d1_1_1 / unk \n",
      "\t\t\t:unk  ( d1_1_1_1 / unk )\n",
      "\t\t)\n",
      "\t\t:unk  ( d1_1_2 / unk \n",
      "\t\t\t:unk  ( d1_1_2_1 / unk )\n",
      "\t\t)\n",
      "\t)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 1, 0, 1, 3, 0, 0, 1, 2, 2]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_without_amr(model_name=model1, tokenizer_path=\"./tokenizers/full_tokenizer.dump\",\n",
    "     data=[(replaced_sentence, deps, [])], max_len=max_len1, embedding_dim=embeddings_dim1, with_reattach=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# now we are going to preprocess a sentence that is has both a Named Entity and a Date Entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "date_time_sentence =\"Andreea is presenting her thesis in July\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'Andreea', u'PERSON'), (u'is', u'O'), (u'presenting', u'O'), (u'her', u'O'), (u'thesis', u'O'), (u'in', u'O'), (u'July', u'O')]\n",
      "[u'PERSON', u'is', u'presenting', u'her', u'thesis', u'in', u'July']\n",
      "PERSON is presenting her thesis in July \n",
      "[(0, [u'Andreea'])]\n"
     ]
    }
   ],
   "source": [
    "(d_t_sentence, named_entities_2) = ner.process_sentence(date_time_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import preprocessing.DateEntitiesReplacer as der"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'PERSON', u'O'), (u'is', u'O'), (u'presenting', u'O'), (u'her', u'O'), (u'thesis', u'O'), (u'in', u'O'), (u'July', u'DATE')]\n",
      "PERSON is presenting her thesis in DATE \n",
      "[(6, [u'July'])]\n"
     ]
    }
   ],
   "source": [
    "(final_sentence, date_entities) = der.process_sentence(d_t_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
