{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from AMRGraph import AMR\n",
    "from AMRData import CustomizedAMR\n",
    "from utilities import pretty_print, generate_action_sequence, generate_custom_amr, generate_amr_with_literals\n",
    "import ActionSequenceGenerator\n",
    "import TokensReplacer\n",
    "import re\n",
    "import itertools\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "amr_string = \"\"\"(c5 / crown-01~e.6\n",
    "      :ARG1 (c / city :wiki \"Hong_Kong\" \n",
    "            :name (n / name :op1 \"Hong\"~e.0 :op2 \"Kong\"~e.1)) \n",
    "      :ARG2~e.7 (l2 / location :wiki - \n",
    "            :name (n2 / name :op1 \"Hollywood\"~e.8 :op2 \"of\"~e.9 :op3 \"the\"~e.10 :op4 \"East\"~e.11)) \n",
    "      :time (a2 / always~e.3))\"\"\"\n",
    "sentence = \"\"\"Hong Kong has always worn the crown of Hollywood of the East .\"\"\"\n",
    "expected = \"\"\"City has always worn the crown of name\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "amr = AMR.parse_string(amr_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mappings between node variables and their corresponding concepts.\n",
      "\n",
      "{'c': 'city', 'n': 'name', 'a2': 'always', 'l2': 'location', 'n2': 'name', 'c5': 'crown-01'}\n",
      "\n",
      "Mappings between nodes and all the aligned tokens: If the nodes don't havea variable (polarity, literals, quantities, interrogatives), they specify both the aligned tokens and the parent in order to uniquely identify them\n",
      "\n",
      "{u'Hong': [(u'0', 'n')], u'of': [(u'9', 'n2')], u'Kong': [(u'1', 'n')], 'a2': ['3'], u'the': [(u'10', 'n2')], u'East': [(u'11', 'n2')], u'Hollywood': [(u'8', 'n2')], 'c5': ['6']}\n",
      "\n",
      "Mappings between relations and tokens. Uniquely identified by also specifying the parent of that relation.\n",
      "\n",
      "{'ARG2': [[('7', 'c5')]]}\n",
      "\n",
      "Mappings from a node to each child, along with the relation between them.\n",
      "\n",
      "Key: Hong\n",
      "Leaf\n",
      "\n",
      "Key: Hong_Kong\n",
      "Leaf\n",
      "\n",
      "Key: a2\n",
      "Leaf\n",
      "\n",
      "Key: Hollywood\n",
      "Leaf\n",
      "\n",
      "Key: n\n",
      "op1 -> Hong\n",
      "op2 -> Kong\n",
      "\n",
      "Key: the\n",
      "Leaf\n",
      "\n",
      "Key: c5\n",
      "ARG1 -> c\n",
      "ARG2 -> l2\n",
      "time -> a2\n",
      "\n",
      "Key: c\n",
      "wiki -> Hong_Kong\n",
      "name -> n\n",
      "\n",
      "Key: East\n",
      "Leaf\n",
      "\n",
      "Key: of\n",
      "Leaf\n",
      "\n",
      "Key: -\n",
      "Leaf\n",
      "\n",
      "Key: Kong\n",
      "Leaf\n",
      "\n",
      "Key: l2\n",
      "wiki -> -\n",
      "name -> n2\n",
      "\n",
      "Key: n2\n",
      "op4 -> East\n",
      "op1 -> Hollywood\n",
      "op2 -> of\n",
      "op3 -> the\n",
      "\n",
      "\n",
      "All the nodes in the amr should appear here.\n",
      "\n",
      "[u'Hong', u'Hong_Kong', 'a2', u'Hollywood', 'n', u'the', 'c5', 'c', u'East', u'of', '-', u'Kong', 'l2', 'n2']\n",
      "\n",
      "Creating custom AMR.\n",
      "\n",
      "\n",
      "Custom AMR token to concepts dict\n",
      "\n",
      "{3: ('a2', 'always'), 6: ('c5', 'crown-01')}\n",
      "\n",
      "Custom AMR relations dict\n",
      "\n",
      "{(u'of', 'n2'): ('op2', [], [u'9']), (u'Hong_Kong', 'c'): ('wiki', [], ''), ('-', 'l2'): ('wiki', [], ''), ('c5', ''): ('', ['c', 'l2', 'a2'], ['6']), ('n', 'c'): ('name', [u'Hong', u'Kong'], ''), (u'Hollywood', 'n2'): ('op1', [], [u'8']), ('c', 'c5'): ('ARG1', [u'Hong_Kong', 'n'], ''), ('l2', 'c5'): ('ARG2', ['-', 'n2'], ''), (u'the', 'n2'): ('op3', [], [u'10']), (u'Hong', 'n'): ('op1', [], [u'0']), (u'East', 'n2'): ('op4', [], [u'11']), (u'Kong', 'n'): ('op2', [], [u'1']), ('a2', 'c5'): ('time', [], ['3']), ('n2', 'l2'): ('name', [u'East', u'Hollywood', u'of', u'the'], '')}\n",
      "\n",
      "Custom AMR parent dict\n",
      "\n",
      "{u'East': 'n2', u'Hong': 'n', u'Hong_Kong': 'c', u'of': 'n2', u'the': 'n2', '-': 'l2', 'c': 'c5', u'Kong': 'n', 'a2': 'c5', 'l2': 'c5', 'n2': 'l2', 'n': 'c', u'Hollywood': 'n2', 'c5': ''}\n"
     ]
    }
   ],
   "source": [
    "custom_amr = generate_custom_amr(amr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find all the nodes which have a :name relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "name_nodes = [(k, amr[k][\"name\"][0]) for k in amr if amr[k] and \"name\" in amr[k]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('c', 'n'), ('l2', 'n2')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find all the literals which span over one named entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "literals_triplets = []\n",
    "for name_tuple in name_nodes:\n",
    "    op_regexp = re.compile(\"^op([0-9])+$\")\n",
    "    name_var = name_tuple[1]\n",
    "    op_rel_list = amr[name_var]\n",
    "    literals = []\n",
    "    for op_rel in op_rel_list:\n",
    "        if op_regexp.match(op_rel):\n",
    "            literals.append(op_rel_list[op_rel][0])\n",
    "    literals_triplets.append((name_tuple[0], name_tuple[1], literals))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we have the following info:\n",
    "The **\"root\" variable of the named entity** (location, person, city, etc.), the **name variable** of the named entity and the **list of literals**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('c', 'n', [u'Hong', u'Kong']),\n",
       " ('l2', 'n2', [u'East', u'Hollywood', u'of', u'the'])]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "literals_triplets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we need to remove, add, replace:\n",
    "\n",
    "From **node_to_concepts**: all the variables corresponding to name\n",
    "\n",
    "From **node_to_tokens**: all the literals. We must replace them with the \"root\" variable of the named entity, pointing to the \"super token\" in which the composing literals are collapsed.\n",
    "\n",
    "From the **amr dict**: All the entries with keys as the name variable or as string literal. We must replace the entry for the \"root\" variable of the name entity with an empty list, as we \"pruned\" its whole subtree. + **remove wiki entries**\n",
    "\n",
    "Must **update the aignment info** of tokens which are to the right of the collapsed literals.\n",
    "\n",
    "Must **hold info about the spanned literals** for each \"super node\" we created.\n",
    "\n",
    "Must **create the new sentence** explictly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First extract info about the spanned tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "named_entities = []\n",
    "for literals_triplet in literals_triplets:\n",
    "    literals_list = literals_triplet[2]\n",
    "    tokens = [int(amr.node_to_tokens[literal][0][0]) for literal in literals_list]\n",
    "    named_entities.append((literals_triplet[0], literals_triplet[1], literals_triplet[2], min(tokens), max(tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('c', 'n', [u'Hong', u'Kong'], 0, 1),\n",
       " ('l2', 'n2', [u'East', u'Hollywood', u'of', u'the'], 8, 11)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "named_entities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The named entities list contains all the information we need.\n",
    "Next step: remove name variables from node_to_concepts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "name_variables = [n[1] for n in named_entities]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['n', 'n2']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "amr.node_to_concepts = dict((key, value) for key, value in amr.node_to_concepts.iteritems() \n",
    "                                        if key not in name_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a2': 'always', 'c': 'city', 'c5': 'crown-01', 'l2': 'location'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amr.node_to_concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove literals from node_to_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "literals = sum([n[2] for n in named_entities], [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'Hong', u'Kong', u'East', u'Hollywood', u'of', u'the']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "literals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "amr.node_to_tokens = dict((key, value) for key, value in amr.node_to_tokens.iteritems() \n",
    "                                        if key not in literals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a2': ['3'], 'c5': ['6']}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amr.node_to_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove name vars and literals from amr dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for l in literals:\n",
    "    if l in amr.keys():\n",
    "        amr.pop(l)\n",
    "for n in name_variables:\n",
    "    if n in amr.keys():\n",
    "        amr.pop(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AMR(util.ListMap,\n",
       "    {'-': ListMap(list, {}),\n",
       "     u'Hong_Kong': ListMap(list, {}),\n",
       "     'a2': ListMap(list, {}),\n",
       "     'c': ListMap(list, {'name': [('n',)], 'wiki': [(u'Hong_Kong',)]}),\n",
       "     'c5': ListMap(list,\n",
       "             {'ARG1': [('c',)], 'ARG2': [('l2',)], 'time': [('a2',)]}),\n",
       "     'l2': ListMap(list, {'name': [('n2',)], 'wiki': [('-',)]})})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update name roots and remove wiki nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "name_roots = [n[0] for n in named_entities]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['c', 'l2']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_roots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for name_root in name_roots:\n",
    "    if \"wiki\" in amr[name_root].keys():\n",
    "        if amr[name_root][\"wiki\"][0] in amr.keys():\n",
    "            amr.pop(amr[name_root][\"wiki\"][0])\n",
    "    amr[name_root] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AMR(util.ListMap,\n",
       "    {'a2': ListMap(list, {}),\n",
       "     'c': [],\n",
       "     'c5': ListMap(list,\n",
       "             {'ARG1': [('c',)], 'ARG2': [('l2',)], 'time': [('a2',)]}),\n",
       "     'l2': []})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add node_to_tokens for the named entities \"roots\", with token as the \"min\" token in the literals group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "named_entities = sorted(named_entities, key=itemgetter(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('c', 'n', [u'Hong', u'Kong'], 0, 1),\n",
       " ('l2', 'n2', [u'East', u'Hollywood', u'of', u'the'], 8, 11)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "named_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tokens = sentence.split(\" \")\n",
    "total_displacement = 0\n",
    "for named_entity in named_entities:\n",
    "    span_min = named_entity[3]\n",
    "    span_max = named_entity[4]\n",
    "    for n in amr.node_to_tokens:\n",
    "        amr.node_to_tokens[n] = [t if int(t) < span_max\n",
    "                                   else int(t) - (span_max - span_min)\n",
    "                                   for t in amr.node_to_tokens[n]]\n",
    "    amr.node_to_tokens[named_entity[0]] = [named_entity[3] - total_displacement]\n",
    "    tokens = [tokens[:(span_min - total_displacement)] + \n",
    "                [amr.node_to_concepts[named_entity[0]]] + \n",
    "                tokens[(span_max - total_displacement + 1):]][0]\n",
    "    total_displacement = total_displacement + span_max - span_min\n",
    "sentence = ' '.join(t for t in tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a2': [2], 'c': [0], 'c5': [5], 'l2': [7]}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amr.node_to_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['city', 'has', 'always', 'worn', 'the', 'crown', 'of', 'location', '.']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'city has always worn the crown of location .'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Another example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "amr_string = \"\"\"(b / become-01~e.6 \n",
    "      :ARG1 (a / area~e.4 \n",
    "            :mod (t / this~e.3)) \n",
    "      :ARG2 (z / zone~e.9 \n",
    "            :ARG1-of (p / prohibit-01~e.8) \n",
    "            :part-of~e.10 (c / city :wiki \"Hong_Kong\" \n",
    "                  :name (n / name :op1 \"Hong\"~e.11 :op2 \"Kong\"~e.12))) \n",
    "      :time (s / since~e.0 \n",
    "            :op1 (t2 / then~e.1)))\"\"\"\n",
    "sentence = \"\"\"Since then , this area has become a prohibited zone in Hong Kong .\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "amr = AMR.parse_string(amr_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(new_amr, new_sentence, named_entities) = TokensReplacer.replace_named_entities(amr, sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('c', 'n', [u'Hong', u'Kong'], 11, 12)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "named_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
