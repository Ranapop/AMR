{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This demo presents the pipeline flow for parsing a sentence into Abstract Meaning Representation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We begin by looking at a sentence and its human-annotated Abstract Meaning Representation graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/silvianac/personalprojects/AMR_lic/plots_keras\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from AMRGraph import AMR\n",
    "from AMRData import CustomizedAMR\n",
    "from utilities import pretty_print, generate_action_sequence, generate_custom_amr\n",
    "import preprocessing.ActionSequenceGenerator as asc\n",
    "from preprocessing.DependencyExtractor import extract_dependencies\n",
    "from preprocessing import TokensReplacer\n",
    "from keras_lstm_flow import test\n",
    "from postprocessing import ActionSequenceReconstruction as asr\n",
    "from smatch import smatch_amr\n",
    "from smatch import smatch_util\n",
    "from deep_dynet import support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model1 = \"proxy_epochs=40_maxlen=20_embeddingsdim=300\"\n",
    "max_len1=20\n",
    "embeddings_dim1=300\n",
    "\n",
    "model2 = \"all_epochs=15_maxlen=30_embeddingsdim=300\"\n",
    "max_len2=30\n",
    "embeddings_dim2=300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./img/demo_simple_example.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentence = \"It looks like we will also bring in whales .\"\n",
    "amr_str = \"\"\"(l / look-02~e.1\n",
    "      :ARG1~e.2 (b / bring-01~e.6\n",
    "            :ARG0 (w / we~e.3)\n",
    "            :ARG1~e.7 (w2 / whale~e.8)\n",
    "            :mod (a / also~e.5)))\"\"\"\n",
    "amr = AMR.parse_string(amr_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mappings between node variables and their corresponding concepts.\n",
      "\n",
      "{'a': 'also', 'b': 'bring-01', 'w2': 'whale', 'w': 'we', 'l': 'look-02'}\n",
      "\n",
      "Mappings between nodes and all the aligned tokens: If the nodes don't havea variable (polarity, literals, quantities, interrogatives), they specify both the aligned tokens and the parent in order to uniquely identify them\n",
      "\n",
      "{'a': ['5'], 'b': ['6'], 'w2': ['8'], 'w': ['3'], 'l': ['1']}\n",
      "\n",
      "Mappings between relations and tokens. Uniquely identified by also specifying the parent of that relation.\n",
      "\n",
      "{'ARG1': [[('7', 'b')], [('2', 'l')]]}\n",
      "\n",
      "Mappings from a node to each child, along with the relation between them.\n",
      "\n",
      "Key: a\n",
      "Leaf\n",
      "\n",
      "Key: b\n",
      "ARG0 -> w\n",
      "ARG1 -> w2\n",
      "mod -> a\n",
      "\n",
      "Key: w2\n",
      "Leaf\n",
      "\n",
      "Key: w\n",
      "Leaf\n",
      "\n",
      "Key: l\n",
      "ARG1 -> b\n",
      "\n",
      "\n",
      "All the nodes in the amr should appear here.\n",
      "\n",
      "['a', 'b', 'w2', 'w', 'l']\n",
      "\n",
      "Creating custom AMR.\n",
      "\n",
      "\n",
      "Custom AMR token to concepts dict\n",
      "\n",
      "{8: ('w2', 'whale'), 1: ('l', 'look-02'), 3: ('w', 'we'), 5: ('a', 'also'), 6: ('b', 'bring-01')}\n",
      "\n",
      "Custom AMR relations dict\n",
      "\n",
      "{('w', 'b'): ('ARG0', [], ['3']), ('b', 'l'): ('ARG1', ['w', 'w2', 'a'], ['6']), ('w2', 'b'): ('ARG1', [], ['8']), ('a', 'b'): ('mod', [], ['5']), ('l', ''): ('', ['b'], ['1'])}\n",
      "\n",
      "Custom AMR parent dict\n",
      "\n",
      "{'a': 'b', 'b': 'l', 'w2': 'b', 'w': 'b', 'l': ''}\n"
     ]
    }
   ],
   "source": [
    "custom_amr = generate_custom_amr(amr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Having the sentence and the CustomAMR structure, we can now generate the <span style=\"color:red\">*oracle action sequence*</span>\n",
    "It looks like we will also bring in whales .\n",
    "```\n",
    "(l / look-02~e.1\n",
    "      :ARG1~e.2 (b / bring-01~e.6\n",
    "            :ARG0 (w / we~e.3)\n",
    "            :ARG1~e.7 (w2 / whale~e.8)\n",
    "            :mod (a / also~e.5)))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "actions = asc.generate_action_sequence(custom_amr, sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DN',\n",
       " 'SH_look-02_l',\n",
       " 'DN',\n",
       " 'SH_we_w',\n",
       " 'DN',\n",
       " 'SH_also_a',\n",
       " 'SH_bring-01_b',\n",
       " 'RL_mod',\n",
       " 'RL_ARG0',\n",
       " 'DN',\n",
       " 'SH_whale_w2',\n",
       " 'RR_ARG1',\n",
       " 'RR_ARG1',\n",
       " 'DN']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We next extract the <span style=\"color:red\">dependencies</span> between the tokens in the sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "deps = extract_dependencies(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It(0) looks(1) like(2) we(3) will(4) also(5) bring(6) in(7) whales(8) ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: (1, 'nsubj'),\n",
       " 2: (6, 'mark'),\n",
       " 3: (6, 'nsubj'),\n",
       " 4: (6, 'aux'),\n",
       " 5: (6, 'advmod'),\n",
       " 6: (1, 'advcl'),\n",
       " 8: (6, 'prep_in')}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We now have all the data necessary for making the prediction using the <span style=\"color:red\">single LSTM model</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model path is:\n",
      "./models/proxy_epochs=40_maxlen=20_embeddingsdim=300\n",
      "Word index len: \n",
      "7107\n",
      "Test data shape: \n",
      "(1, 10)\n",
      "(1, 14)\n",
      "(1,)\n",
      "1\n",
      "Found 400000 word vectors.\n",
      "Embedding match for volume-quantity\n",
      "Embedding match for distance-quantity\n",
      "Embedding match for energy-quantity\n",
      "Embedding match for power-quantity\n",
      "Embedding match for mass-quantity\n",
      "Embedding match for monetary-quantity\n",
      "Embedding match for temporal-quantity\n",
      "Embedding match for date-entity\n",
      "Not found: ['around~', 'blowjobs', \"don'cha\", 'it...', 'dumbfuck', 'statement/report', '25+', 'booyah', 'railway-line', 'though...', 'decisiohttp://www.historyofwar.org/articles/wars_downfall3.htmln', \"'?\", '\\'\"', \"'.\", 'href=\"http://themamas.org/about-the-madison-area-music-awards/mission-vision-statements/\">', 'miscoding', 'colenel', 'obamabots', '............', '!!!!!!', 'k00', 'http://news.cnet.com/8301-1035_3-57572850-94/doj-lets-important-deadline-pass-in-t-mobile-metropcs-deal/', 'remaning', 'theblaze.com', 'nannystate', 'right..', 'http://www.bradblog.com/?p=7906', \"'s...\", 'political-party', 'lastly..', 'href=\"http://www.youtube.com/watch?v=eqg1hu0pmg0\">', 'href=\"http://www.mideastweb.org/palpop.htm\">', 'class..', '((', 'href=\"http://dictionary.reference.com/browse/charity\">', 'yayn', 'sakeenah', 'href=\"http://www.gwu.edu/~nsarchiv/nsaebb/nsaebb162/index.htm\">', 'href=\"http://www.ndp.ca/platform/healthcare\">', 'one....', 'gimmmeeeee', 'fianlly', 'esrp', 'batshit', '.\\xe2\\x80\\x9d', \"isn't...\", 'crapola', 'audasity', '...where', '****', '2h2', 'yes..', 'hmm...good', 'head~', 'whackjobs', 'mmmk', 'know..', 'rofl', ')\"', 'criminal-organization', '<a', '\"?!?!', 'might~', 'href=\"http://science.nasa.gov/newhome/headlines/essd06oct97_1.htm\">', 'http://www.representativepress.org/israelhistory.html', 'href=\"http://cthealth.server101.com/the_case_for_universal_health_care_in_the_united_states.htm\">', 'goooooood', 'spin..', 'securitynet', 'minutiea', 'libbs', 'ethnic-group', 'worship-place', '<--', 'wedgy', 'resarch', 'evinidence', 'anaonymous', 'imho', '#10', 'natural-object', '=/', 'numpty', 'conservs', '225k', 'though..', 'dumb...', '//www.youtube.com/watch', 'out..', 'grats', '\\xc2\\xa7', 'victims\\xe2\\x84\\xa2.', '3,794,100', 'nutjob', 'times..', 'href=\"http://whatreallyhappened.com/wrharticles/pearl/www.geocities.com/pentagon/6315/fdr.html\">', 'bday', '......', 'dumbass', 'href=\"http://news.cnet.com/8301-1035_3-57572850-94/doj-lets-important-deadline-pass-in-t-mobile-metropcs-deal/\">', 'moonbats', 'them..', 'href=\"http://www.wired.com/wiredscience/2008/03/colbert-and-kam/\">', 'dipshit', '.............', '!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!', 'accusatio', 'funny...', 'href=\"http://nation.foxnews.com/ft-hood-shooting/2011/12/07/obama-regime-calls-ft-hood-shooting-workplace-violence\">', 'occsassionally', 'temperatures.?', 'amusement-park', 'david...', '17189', 'trng', '534446433', 'foresnics', 'href=\"http://visiontoamerica.org/5959/gingrich-i-helped-defeat-communism/\">', 'ignorants', 'href=\"http://www.businessweek.com/articles/2012-03-16/wanted-more-ceos-in-washington\">', '???????????', 'typo--yes', '********************************', 'me......', 'asshat', 'out...', 'indisputible', 'tless', 'href=\"http://www.factcheck.org/2008/01/clinton-passed-on-killing-bin-laden/\">', 'reamain', 'href=\"http://www.sakeenah.org/celebrate.shtml\">', 'slammed..', '-@', '->', 'country-region', 'editec', 'gulty', '@-', '..........', 'nycarbineer', '****ing', 'phear', 'goals=', '****.', 'educated(?)', '*passes', 'http://www.themamas.org/', '\"..', 'indeciperable', 'href=\"http://cnsnews.com/node/464826\">', 'religious-group', 'tatements/', \"'....\", '???????', 'political-movement', 'ok..', '^^case', '</a>', '#name', '.)', '..', '.\"', 'liar..', 'overwhelingly', 'href=\"http://www.snopes.com/rumors/clinton.asp\">', '*******', '.......', 'href=\"http://www.avert.org/aids-history-america.htm\">', 'dosent', '\\xe2\\x80\\x9d.', '\\xe2\\x80\\x9d?', 'attrocious', 'about.?', 'ilogical', 'about..', 'ummmmm', 'a.d.?', 'href=\"http://www.themamas.org/\">', 'afelm', 'cringeworthy', 'taxes..', 'href=\"http://www.counterpunch.org/2011/12/02/debt-slavery-%e2%80%93-why-it-destroyed-rome-why-it-will-destroy-us-unless-it%e2%80%99s-stopped/\">', '**edit**', 'href=\"http://www.britannica.com/ebchecked/topic/89739/caliphate\">', 'bwahahahaaa', 'inacurate', 'negs', 'href=\"http://www.businessinsider.com/cornell-wins-bloombergs-nyc-tech-campus-heres-what-the-2-million-square-foot-school-will-look-like-2011-12\">', ':wink', 'immie', 'historicall', 'pusses', 'broadcast-program', '0.00525', 'negged', 'href=\"http://www.newscientist.com/article/dn14527-climate-myths-global-warming-stopped-in-1998.html\">', 'gunna', 'pussies', 'http://www.mideastweb.org/palpop.htm', 'href=\"http://video.foxnews.com/v/3982487/live-free-or-die\">', 'dear..', 'href=\"http://www.bradblog.com/?p=7906\">', 'oil..', 'href=\"mailto:elrushbo@eibnet.com\">', 'href=\"http://www.plannedparenthood.org/health-center/centerdetails.asp?f=3945&a=90070&v=details\">', 'to..', 'sourcewatch', '...and', 'href=\"http://www.latimes.com/world/worldnow/la-fg-wn-suicide-bomber-pakistan-20130922,0,923285.story\">', 'car-make', 'oohhhhhh', 'local-region', 'blog-01', 'work-of-art', 'href=\"http://www.adl.org/holocaust/weber.asp\">', 'dyspraxia', 'definate', 'innit', 'shoot-02', 'marccy', 'asswipe', 'true..', '??????????', \"rw'er\", 'srsly', '//www.vanityfair.com/commentary/content/articles/050411roco03c', 'indesputable', 'href=\"http://www.law.umkc.edu/faculty/projects/ftrials/conlaw/rightofprivacy.html\">', 'oo0o', '!!???', 'a....well', 'halarious', 'href=\"http://scienceblogs.com/gregladen/2011/03/the_fukushima_disaster_hyperbo.php?utm_source=networkbanner&utm_medium=link\">', 'up..', 'baddy', 'shitstain', 'excusatio', 'governmenht', 'href=\"http://www.democracynow.org/2011/2/15/obamas_37_trillion_budget_calls_for\">', 'christianoid', 'petita', 'lable', 'carrry', '..............', 'sandy..', 'strawmanning', 'country..', 'paulestinian', 'href=\"http://www.usmessageboard.com/4267872-post42.html\">', 'nerly', '!!!!!!!', 'lulz', 'weapon..', 'href=\"http://www.youtube.com/watch?v=nz5amhi9g7o\">', 'blowjob', 'natural-disaster', 'pe4', 'course..', 'so....who', 'href=\"http://en.wikipedia.org/wiki/fallacy\">', '@:@', 'pgpcoder', '.........', 'href=\"http://www.salon.com/news/1998/03/cov_12news.html\">', 'warmist', '970000', 'market-sector', 'happned', 'href=\"http://www.snopes.com/quotes/internet.asp\">', \"won't\", 'excuses..', 'sports-facility', 'fauxtography', 'inherrently', 'prodiction', 'itelf', 'thankies', 'right...', '*no*', 'fuckwhit', 'dufus', 'actaul', \"s'okay\", 'ayup', 'allll', 'href=\"http://www.decisionsonevidence.com/2011/10/do-regulations-curtail-job-growth/\">', '1234567', 'is..', 'not..', 'skaptiks', 'toiba', 'turdboat', 'soon...', 'href=\"http://prospect.org/article/why-we-need-occupy-wall-street?utm_source=daily+digest&utm_campaign=39ed4689d6-dd_11_16_1111_16_2011&utm_medium=email\">', 'rule-01', 'href=\"http://www.theblaze.com/stories/beck-doesnt-hold-back-in-gingrich-interview-tough-questions-on-mandates-big-govt-and-global-warming/\">', 'huuuge', 'href=\"http://cnsnews.com/news/article/half-unemployment-rate-decline-due-people-giving-job-search-labor-data-show\">', 'href=\"http://democratherald.com/news/opinion/editorial/editorial-once-again-fluoridation/article_e82f150c-6263-11e1-aab4-001871e3ce6c.html#ixzz1o0ksmtvn\">', 'href=\"http://www.votersunite.org/info/es&sinthenews.pdf\">', '\"...', 'bwahahahaa', 'ransomware', '~shakes', 'now..', \"havn't\", 'aircraft-type', 'twoofer', '\"~', 'contracption', '\",', '\".', '\"?', 'nutbag', 'regretable', 'slowy', 'world-region', '[/', \"ain't\", '@-@', 'v=iaadvod2srq', 'llocks', 'motherfucking', 'miniture', 'intergency', 'pay..', 'tbh', 'nowhatimean', '?????????????', 'elrushbo@eibnet.com', 'raincloud', '^^^', 'music-key', 'aeroplace', \"y'all\", 'dickhead', '#9', '#8', '#3', '#2', '#1', '#7', '#5', '#4', '@/@', 'said..', 'http://www.votersunite.org/info/es&sinthenews.pdf', 'braniac', 'mehbeh', '303.00', 'ehh', '75+', 'tickee', 'neithe', 'admittted', 'helloo000', '????????', 'point^^', 'href=\"http://members.iinet.net.au/~gduncan/massacres_pacific.html\">', 'href=\"http://mochamanual.com/mochamanual/trying-to-conceive/are-your-fortified-the-facts-about-folic-acid-what-every-black-woman-needs-to-know.html\">', 'obummer', 'oralloy', 'href=\"http://www.digitalhistory.uh.edu/do_history/decisions/hiroshima.html\">', 'cmpanies', 'won\\xe2\\x80\\x99t', 'regional-group', 'htis', 'cannont', 'braawwk', 'crocidolite', 'rediculous', '!!!.....', 'not...it', '25,28,32', 'jail...', 'puhleeze', 'href=\"http://www.usmessageboard.com/attachments/politics/17189-is-the-media-in-the-bag-for-newt-head_up.jpg\">', 'typical...', 'hahahaha', 'scan..', 'crazy..', 'pubication', '8.', 'anyhoo', 'http://themamas.org/about-the-madison-a...', 'wittle', 'lepruchauns', 'braawwkkk', 'stumped..', 'hehehe', 'interviened', 'no\\xe2\\x80\\xa6', 'research-institute', 'city-district', 'href=\"http://www.latimes.com/news/politics/la-pn-obama-clinton-most-admired-gallup-20111227,0,4670281.story\">', 'nucleic-acid', '!!!!!!1', 'qudea', 'zro2', 'government-organization', 'sustainingly', '18701954600', 'case..', 'href=\"http://www.representativepress.org/israelhistory.html\">']\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 20)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_2 (InputLayer)             (None, 20)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_3 (InputLayer)             (None, 20)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_4 (InputLayer)             (None, 20)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)          (None, 20, 300)       2132700                                      \n",
      "____________________________________________________________________________________________________\n",
      "input_5 (InputLayer)             (None, 20, 5)         0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_6 (InputLayer)             (None, 20, 6)         0                                            \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)      (None, 20, 1211)      0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                    (None, 20, 1024)      9158656                                      \n",
      "____________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistribu (None, 20, 5)         5125                                         \n",
      "====================================================================================================\n",
      "Total params: 11,296,481.0\n",
      "Trainable params: 9,163,781.0\n",
      "Non-trainable params: 2,132,700.0\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 20)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_2 (InputLayer)             (None, 20)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_3 (InputLayer)             (None, 20)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_4 (InputLayer)             (None, 20)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)          (None, 20, 300)       2132700                                      \n",
      "____________________________________________________________________________________________________\n",
      "input_5 (InputLayer)             (None, 20, 5)         0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_6 (InputLayer)             (None, 20, 6)         0                                            \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)      (None, 20, 1211)      0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                    (None, 20, 1024)      9158656                                      \n",
      "____________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistribu (None, 20, 5)         5125                                         \n",
      "====================================================================================================\n",
      "Total params: 11,296,481.0\n",
      "Trainable params: 9,163,781.0\n",
      "Non-trainable params: 2,132,700.0\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "Buffer and stack at end of prediction\n",
      "[]\n",
      "[610]\n",
      "Sentence\n",
      "it looks like we will also bring in whales . \n",
      "\n",
      "Predicted\n",
      "DN SH SH SH RL DN SH SH RL DN RR DN DN RR \n",
      "\n",
      "Actual\n",
      "DN SH DN SH DN SH SH RL RL DN SH RR RR DN \n",
      "\n",
      "Predictions with old labels: \n",
      "['DN', 'SH_look-02', 'SH_we', 'SH_also', 'RL_mod', 'DN', 'SH_bring-01', 'SH_whale', 'RL_ARG0', 'DN', 'RR_ARG1', 'DN', 'DN', 'RR_ARG1']\n",
      "Original Amr\n",
      "(l / look-02~e.1\n",
      "      :ARG1~e.2 (b / bring-01~e.6\n",
      "            :ARG0 (w / we~e.3)\n",
      "            :ARG1~e.7 (w2 / whale~e.8)\n",
      "            :mod (a / also~e.5)))\n",
      "Predicted Amr\n",
      "( d1 / look-02 \n",
      "\t:ARG1  ( d1_1 / also \n",
      "\t\t:mod  ( d1_1_1 / we )\n",
      "\t\t:ARG1  ( d1_1_2 / whale \n",
      "\t\t\t:ARG0  ( d1_1_2_1 / bring-01 )\n",
      "\t\t)\n",
      "\t)\n",
      ")\n",
      "Smatch f-score 0.600000\n",
      "1/1 [==============================] - 0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[3, 0, 0, 0, 1, 3, 0, 0, 1, 3, 2, 3, 3, 2]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(model_name=model1, tokenizer_path=\"./tokenizers/full_tokenizer.dump\",\n",
    "     data=[(sentence, actions, amr_str, deps)], max_len=max_len1, embedding_dim=embeddings_dim1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We now look at a more complex example, which also contains a <span style=\"color:red\">Named-Entity</span>.  Named entities are identified and replaced at preprocessing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./img/demo_ne_example.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentence = \"upgrade fire control systems of Indian tanks .\"\n",
    "\n",
    "amr_str= \"\"\"(u / upgrade-02~e.0 \n",
    "      :ARG1 (s / system~e.3 \n",
    "            :ARG0-of (c / control-01~e.2 \n",
    "                  :ARG1 (f / fire-01~e.1)) \n",
    "            :poss~e.4 (t / tank~e.6 \n",
    "                  :mod (c2 / country :wiki \"India\" \n",
    "                        :name (n / name :op1 \"India\"~e.5)))))\"\"\"\n",
    "amr = AMR.parse_string(amr_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We replace the named-entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "concepts_metadata = {}\n",
    "(new_amr, new_sentence, named_entities) = TokensReplacer.replace_named_entities(amr, sentence)\n",
    "for name_entity in named_entities:\n",
    "    concepts_metadata[name_entity[0]] = name_entity[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'upgrade fire control systems of country tanks .'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AMR(util.ListMap,\n",
       "    {u'India': ListMap(list, {}),\n",
       "     'c': ListMap(list, {'ARG1': [('f',)]}),\n",
       "     'c2': ListMap(list, {'name': [('n',)], 'wiki': [(u'India',)]}),\n",
       "     'f': ListMap(list, {}),\n",
       "     'n': ListMap(list, {'op1': [(u'India',)]}),\n",
       "     's': ListMap(list, {'ARG0-of': [('c',)], 'poss': [('t',)]}),\n",
       "     't': ListMap(list, {'mod': [('c2',)]}),\n",
       "     'u': ListMap(list, {'ARG1': [('s',)]})})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('c2', 'n', [u'India'], 5, 5, <amr_util.Node.Node instance at 0x1360dd098>)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "named_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AMR(util.ListMap,\n",
       "    {'c': ListMap(list, {'ARG1': [('f',)]}),\n",
       "     'c2': {},\n",
       "     'f': ListMap(list, {}),\n",
       "     's': ListMap(list, {'ARG0-of': [('c',)], 'poss': [('t',)]}),\n",
       "     't': ListMap(list, {'mod': [('c2',)]}),\n",
       "     'u': ListMap(list, {'ARG1': [('s',)]})})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_amr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "( d1 / country \n",
      "\t:name  ( d1_1 / name \n",
      "\t\t:op1 \"\"India\"\"\n",
      "\t)\n",
      "\t:wiki \"\"India\"\"\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print concepts_metadata['c2'].amr_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We now generate the action sequence for the preprocessed AMR graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mappings between node variables and their corresponding concepts.\n",
      "\n",
      "{'c': 'control-01', 'f': 'fire-01', 's': 'system', 'u': 'upgrade-02', 't': 'tank', 'c2': 'country'}\n",
      "\n",
      "Mappings between nodes and all the aligned tokens: If the nodes don't havea variable (polarity, literals, quantities, interrogatives), they specify both the aligned tokens and the parent in order to uniquely identify them\n",
      "\n",
      "{'c': ['2'], 'f': ['1'], 's': ['3'], 'u': ['0'], 't': ['6'], 'c2': [5]}\n",
      "\n",
      "Mappings between relations and tokens. Uniquely identified by also specifying the parent of that relation.\n",
      "\n",
      "{'poss': [[('4', 's')]]}\n",
      "\n",
      "Mappings from a node to each child, along with the relation between them.\n",
      "\n",
      "Key: c\n",
      "ARG1 -> f\n",
      "\n",
      "Key: f\n",
      "Leaf\n",
      "\n",
      "Key: s\n",
      "ARG0-of -> c\n",
      "poss -> t\n",
      "\n",
      "Key: u\n",
      "ARG1 -> s\n",
      "\n",
      "Key: t\n",
      "mod -> c2\n",
      "\n",
      "Key: c2\n",
      "Leaf\n",
      "\n",
      "\n",
      "All the nodes in the amr should appear here.\n",
      "\n",
      "['c', 'f', 's', 'u', 't', 'c2']\n",
      "\n",
      "Creating custom AMR.\n",
      "\n",
      "\n",
      "Custom AMR token to concepts dict\n",
      "\n",
      "{0: ('u', 'upgrade-02'), 1: ('f', 'fire-01'), 2: ('c', 'control-01'), 3: ('s', 'system'), 5: ('c2', 'country'), 6: ('t', 'tank')}\n",
      "\n",
      "Custom AMR relations dict\n",
      "\n",
      "{('c', 's'): ('ARG0-of', ['f'], ['2']), ('u', ''): ('', ['s'], ['0']), ('c2', 't'): ('mod', [], [5]), ('t', 's'): ('poss', ['c2'], ['6']), ('s', 'u'): ('ARG1', ['c', 't'], ['3']), ('f', 'c'): ('ARG1', [], ['1'])}\n",
      "\n",
      "Custom AMR parent dict\n",
      "\n",
      "{'c': 's', 'f': 'c', 's': 'u', 'u': '', 't': 's', 'c2': 't'}\n"
     ]
    }
   ],
   "source": [
    "custom_amr = generate_custom_amr(new_amr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "actions = asc.generate_action_sequence(custom_amr, new_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SH_upgrade-02_u',\n",
       " 'SH_fire-01_f',\n",
       " 'SH_control-01_c',\n",
       " 'RL_ARG1',\n",
       " 'SH_system_s',\n",
       " 'RL_ARG0-of',\n",
       " 'DN',\n",
       " 'SH_country_c2',\n",
       " 'SH_tank_t',\n",
       " 'RL_mod',\n",
       " 'RR_poss',\n",
       " 'RR_ARG1',\n",
       " 'DN']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "deps = extract_dependencies(new_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: (3, 'nn'), 2: (3, 'nn'), 3: (0, 'dobj'), 5: (6, 'nn'), 6: (3, 'prep_of')}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model path is:\n",
      "./models/proxy_epochs=40_maxlen=20_embeddingsdim=300\n",
      "Word index len: \n",
      "7107\n",
      "Test data shape: \n",
      "(1, 8)\n",
      "(1, 13)\n",
      "(1,)\n",
      "1\n",
      "Found 400000 word vectors.\n",
      "Embedding match for volume-quantity\n",
      "Embedding match for distance-quantity\n",
      "Embedding match for energy-quantity\n",
      "Embedding match for power-quantity\n",
      "Embedding match for mass-quantity\n",
      "Embedding match for monetary-quantity\n",
      "Embedding match for temporal-quantity\n",
      "Embedding match for date-entity\n",
      "Not found: ['around~', 'blowjobs', \"don'cha\", 'it...', 'dumbfuck', 'statement/report', '25+', 'booyah', 'railway-line', 'though...', 'decisiohttp://www.historyofwar.org/articles/wars_downfall3.htmln', \"'?\", '\\'\"', \"'.\", 'href=\"http://themamas.org/about-the-madison-area-music-awards/mission-vision-statements/\">', 'miscoding', 'colenel', 'obamabots', '............', '!!!!!!', 'k00', 'http://news.cnet.com/8301-1035_3-57572850-94/doj-lets-important-deadline-pass-in-t-mobile-metropcs-deal/', 'remaning', 'theblaze.com', 'nannystate', 'right..', 'http://www.bradblog.com/?p=7906', \"'s...\", 'political-party', 'lastly..', 'href=\"http://www.youtube.com/watch?v=eqg1hu0pmg0\">', 'href=\"http://www.mideastweb.org/palpop.htm\">', 'class..', '((', 'href=\"http://dictionary.reference.com/browse/charity\">', 'yayn', 'sakeenah', 'href=\"http://www.gwu.edu/~nsarchiv/nsaebb/nsaebb162/index.htm\">', 'href=\"http://www.ndp.ca/platform/healthcare\">', 'one....', 'gimmmeeeee', 'fianlly', 'esrp', 'batshit', '.\\xe2\\x80\\x9d', \"isn't...\", 'crapola', 'audasity', '...where', '****', '2h2', 'yes..', 'hmm...good', 'head~', 'whackjobs', 'mmmk', 'know..', 'rofl', ')\"', 'criminal-organization', '<a', '\"?!?!', 'might~', 'href=\"http://science.nasa.gov/newhome/headlines/essd06oct97_1.htm\">', 'http://www.representativepress.org/israelhistory.html', 'href=\"http://cthealth.server101.com/the_case_for_universal_health_care_in_the_united_states.htm\">', 'goooooood', 'spin..', 'securitynet', 'minutiea', 'libbs', 'ethnic-group', 'worship-place', '<--', 'wedgy', 'resarch', 'evinidence', 'anaonymous', 'imho', '#10', 'natural-object', '=/', 'numpty', 'conservs', '225k', 'though..', 'dumb...', '//www.youtube.com/watch', 'out..', 'grats', '\\xc2\\xa7', 'victims\\xe2\\x84\\xa2.', '3,794,100', 'nutjob', 'times..', 'href=\"http://whatreallyhappened.com/wrharticles/pearl/www.geocities.com/pentagon/6315/fdr.html\">', 'bday', '......', 'dumbass', 'href=\"http://news.cnet.com/8301-1035_3-57572850-94/doj-lets-important-deadline-pass-in-t-mobile-metropcs-deal/\">', 'moonbats', 'them..', 'href=\"http://www.wired.com/wiredscience/2008/03/colbert-and-kam/\">', 'dipshit', '.............', '!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!', 'accusatio', 'funny...', 'href=\"http://nation.foxnews.com/ft-hood-shooting/2011/12/07/obama-regime-calls-ft-hood-shooting-workplace-violence\">', 'occsassionally', 'temperatures.?', 'amusement-park', 'david...', '17189', 'trng', '534446433', 'foresnics', 'href=\"http://visiontoamerica.org/5959/gingrich-i-helped-defeat-communism/\">', 'ignorants', 'href=\"http://www.businessweek.com/articles/2012-03-16/wanted-more-ceos-in-washington\">', '???????????', 'typo--yes', '********************************', 'me......', 'asshat', 'out...', 'indisputible', 'tless', 'href=\"http://www.factcheck.org/2008/01/clinton-passed-on-killing-bin-laden/\">', 'reamain', 'href=\"http://www.sakeenah.org/celebrate.shtml\">', 'slammed..', '-@', '->', 'country-region', 'editec', 'gulty', '@-', '..........', 'nycarbineer', '****ing', 'phear', 'goals=', '****.', 'educated(?)', '*passes', 'http://www.themamas.org/', '\"..', 'indeciperable', 'href=\"http://cnsnews.com/node/464826\">', 'religious-group', 'tatements/', \"'....\", '???????', 'political-movement', 'ok..', '^^case', '</a>', '#name', '.)', '..', '.\"', 'liar..', 'overwhelingly', 'href=\"http://www.snopes.com/rumors/clinton.asp\">', '*******', '.......', 'href=\"http://www.avert.org/aids-history-america.htm\">', 'dosent', '\\xe2\\x80\\x9d.', '\\xe2\\x80\\x9d?', 'attrocious', 'about.?', 'ilogical', 'about..', 'ummmmm', 'a.d.?', 'href=\"http://www.themamas.org/\">', 'afelm', 'cringeworthy', 'taxes..', 'href=\"http://www.counterpunch.org/2011/12/02/debt-slavery-%e2%80%93-why-it-destroyed-rome-why-it-will-destroy-us-unless-it%e2%80%99s-stopped/\">', '**edit**', 'href=\"http://www.britannica.com/ebchecked/topic/89739/caliphate\">', 'bwahahahaaa', 'inacurate', 'negs', 'href=\"http://www.businessinsider.com/cornell-wins-bloombergs-nyc-tech-campus-heres-what-the-2-million-square-foot-school-will-look-like-2011-12\">', ':wink', 'immie', 'historicall', 'pusses', 'broadcast-program', '0.00525', 'negged', 'href=\"http://www.newscientist.com/article/dn14527-climate-myths-global-warming-stopped-in-1998.html\">', 'gunna', 'pussies', 'http://www.mideastweb.org/palpop.htm', 'href=\"http://video.foxnews.com/v/3982487/live-free-or-die\">', 'dear..', 'href=\"http://www.bradblog.com/?p=7906\">', 'oil..', 'href=\"mailto:elrushbo@eibnet.com\">', 'href=\"http://www.plannedparenthood.org/health-center/centerdetails.asp?f=3945&a=90070&v=details\">', 'to..', 'sourcewatch', '...and', 'href=\"http://www.latimes.com/world/worldnow/la-fg-wn-suicide-bomber-pakistan-20130922,0,923285.story\">', 'car-make', 'oohhhhhh', 'local-region', 'blog-01', 'work-of-art', 'href=\"http://www.adl.org/holocaust/weber.asp\">', 'dyspraxia', 'definate', 'innit', 'shoot-02', 'marccy', 'asswipe', 'true..', '??????????', \"rw'er\", 'srsly', '//www.vanityfair.com/commentary/content/articles/050411roco03c', 'indesputable', 'href=\"http://www.law.umkc.edu/faculty/projects/ftrials/conlaw/rightofprivacy.html\">', 'oo0o', '!!???', 'a....well', 'halarious', 'href=\"http://scienceblogs.com/gregladen/2011/03/the_fukushima_disaster_hyperbo.php?utm_source=networkbanner&utm_medium=link\">', 'up..', 'baddy', 'shitstain', 'excusatio', 'governmenht', 'href=\"http://www.democracynow.org/2011/2/15/obamas_37_trillion_budget_calls_for\">', 'christianoid', 'petita', 'lable', 'carrry', '..............', 'sandy..', 'strawmanning', 'country..', 'paulestinian', 'href=\"http://www.usmessageboard.com/4267872-post42.html\">', 'nerly', '!!!!!!!', 'lulz', 'weapon..', 'href=\"http://www.youtube.com/watch?v=nz5amhi9g7o\">', 'blowjob', 'natural-disaster', 'pe4', 'course..', 'so....who', 'href=\"http://en.wikipedia.org/wiki/fallacy\">', '@:@', 'pgpcoder', '.........', 'href=\"http://www.salon.com/news/1998/03/cov_12news.html\">', 'warmist', '970000', 'market-sector', 'happned', 'href=\"http://www.snopes.com/quotes/internet.asp\">', \"won't\", 'excuses..', 'sports-facility', 'fauxtography', 'inherrently', 'prodiction', 'itelf', 'thankies', 'right...', '*no*', 'fuckwhit', 'dufus', 'actaul', \"s'okay\", 'ayup', 'allll', 'href=\"http://www.decisionsonevidence.com/2011/10/do-regulations-curtail-job-growth/\">', '1234567', 'is..', 'not..', 'skaptiks', 'toiba', 'turdboat', 'soon...', 'href=\"http://prospect.org/article/why-we-need-occupy-wall-street?utm_source=daily+digest&utm_campaign=39ed4689d6-dd_11_16_1111_16_2011&utm_medium=email\">', 'rule-01', 'href=\"http://www.theblaze.com/stories/beck-doesnt-hold-back-in-gingrich-interview-tough-questions-on-mandates-big-govt-and-global-warming/\">', 'huuuge', 'href=\"http://cnsnews.com/news/article/half-unemployment-rate-decline-due-people-giving-job-search-labor-data-show\">', 'href=\"http://democratherald.com/news/opinion/editorial/editorial-once-again-fluoridation/article_e82f150c-6263-11e1-aab4-001871e3ce6c.html#ixzz1o0ksmtvn\">', 'href=\"http://www.votersunite.org/info/es&sinthenews.pdf\">', '\"...', 'bwahahahaa', 'ransomware', '~shakes', 'now..', \"havn't\", 'aircraft-type', 'twoofer', '\"~', 'contracption', '\",', '\".', '\"?', 'nutbag', 'regretable', 'slowy', 'world-region', '[/', \"ain't\", '@-@', 'v=iaadvod2srq', 'llocks', 'motherfucking', 'miniture', 'intergency', 'pay..', 'tbh', 'nowhatimean', '?????????????', 'elrushbo@eibnet.com', 'raincloud', '^^^', 'music-key', 'aeroplace', \"y'all\", 'dickhead', '#9', '#8', '#3', '#2', '#1', '#7', '#5', '#4', '@/@', 'said..', 'http://www.votersunite.org/info/es&sinthenews.pdf', 'braniac', 'mehbeh', '303.00', 'ehh', '75+', 'tickee', 'neithe', 'admittted', 'helloo000', '????????', 'point^^', 'href=\"http://members.iinet.net.au/~gduncan/massacres_pacific.html\">', 'href=\"http://mochamanual.com/mochamanual/trying-to-conceive/are-your-fortified-the-facts-about-folic-acid-what-every-black-woman-needs-to-know.html\">', 'obummer', 'oralloy', 'href=\"http://www.digitalhistory.uh.edu/do_history/decisions/hiroshima.html\">', 'cmpanies', 'won\\xe2\\x80\\x99t', 'regional-group', 'htis', 'cannont', 'braawwk', 'crocidolite', 'rediculous', '!!!.....', 'not...it', '25,28,32', 'jail...', 'puhleeze', 'href=\"http://www.usmessageboard.com/attachments/politics/17189-is-the-media-in-the-bag-for-newt-head_up.jpg\">', 'typical...', 'hahahaha', 'scan..', 'crazy..', 'pubication', '8.', 'anyhoo', 'http://themamas.org/about-the-madison-a...', 'wittle', 'lepruchauns', 'braawwkkk', 'stumped..', 'hehehe', 'interviened', 'no\\xe2\\x80\\xa6', 'research-institute', 'city-district', 'href=\"http://www.latimes.com/news/politics/la-pn-obama-clinton-most-admired-gallup-20111227,0,4670281.story\">', 'nucleic-acid', '!!!!!!1', 'qudea', 'zro2', 'government-organization', 'sustainingly', '18701954600', 'case..', 'href=\"http://www.representativepress.org/israelhistory.html\">']\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_7 (InputLayer)             (None, 20)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_8 (InputLayer)             (None, 20)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_9 (InputLayer)             (None, 20)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_10 (InputLayer)            (None, 20)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)          (None, 20, 300)       2132700                                      \n",
      "____________________________________________________________________________________________________\n",
      "input_11 (InputLayer)            (None, 20, 5)         0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_12 (InputLayer)            (None, 20, 6)         0                                            \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)      (None, 20, 1211)      0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                    (None, 20, 1024)      9158656                                      \n",
      "____________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistribu (None, 20, 5)         5125                                         \n",
      "====================================================================================================\n",
      "Total params: 11,296,481.0\n",
      "Trainable params: 9,163,781.0\n",
      "Non-trainable params: 2,132,700.0\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_7 (InputLayer)             (None, 20)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_8 (InputLayer)             (None, 20)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_9 (InputLayer)             (None, 20)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_10 (InputLayer)            (None, 20)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)          (None, 20, 300)       2132700                                      \n",
      "____________________________________________________________________________________________________\n",
      "input_11 (InputLayer)            (None, 20, 5)         0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_12 (InputLayer)            (None, 20, 6)         0                                            \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)      (None, 20, 1211)      0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                    (None, 20, 1024)      9158656                                      \n",
      "____________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistribu (None, 20, 5)         5125                                         \n",
      "====================================================================================================\n",
      "Total params: 11,296,481.0\n",
      "Trainable params: 9,163,781.0\n",
      "Non-trainable params: 2,132,700.0\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "Buffer and stack at end of prediction\n",
      "[]\n",
      "[2656]\n",
      "Sentence\n",
      "upgrade fire control systems of country tanks . \n",
      "\n",
      "Predicted\n",
      "SH SH SH RL SH RL DN SH SH RL RR DN RR \n",
      "\n",
      "Actual\n",
      "SH SH SH RL SH RL DN SH SH RL RR RR DN \n",
      "\n",
      "Predictions with old labels: \n",
      "['SH_upgrade-02', 'SH_fire-01', 'SH_control-01', 'RL_ARG1', 'SH_system', 'RL_ARG0-of', 'DN', 'SH_country', 'SH_tank', 'RL_mod', 'RR_poss', 'DN', 'RR_ARG1']\n",
      "Original Amr\n",
      "(u / upgrade-02~e.0 \n",
      "      :ARG1 (s / system~e.3 \n",
      "            :ARG0-of (c / control-01~e.2 \n",
      "                  :ARG1 (f / fire-01~e.1)) \n",
      "            :poss~e.4 (t / tank~e.6 \n",
      "                  :mod (c2 / country :wiki \"India\" \n",
      "                        :name (n / name :op1 \"India\"~e.5)))))\n",
      "Predicted Amr\n",
      "( d1 / upgrade-02 \n",
      "\t:ARG1  ( d1_1 / system \n",
      "\t\t:ARG0-of  ( d1_1_1 / control-01 \n",
      "\t\t\t:ARG1  ( d1_1_1_1 / fire-01 )\n",
      "\t\t)\n",
      "\t\t:poss  ( d1_1_2 / tank \n",
      "\t\t\t:mod  ( d1_1_2_1 / country )\n",
      "\t\t)\n",
      "\t)\n",
      ")\n",
      "Smatch f-score 0.857143\n",
      "1/1 [==============================] - 0s\n"
     ]
    }
   ],
   "source": [
    "predictions = test(model_name=model1, tokenizer_path=\"./tokenizers/full_tokenizer.dump\",\n",
    "     data=[(new_sentence, actions, amr_str, deps)], max_len=max_len1, embedding_dim=embeddings_dim1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Our score is penalized by the fact that the whole Named-Entity subtree is pruned. We now show how the subtree is recovered based on the named entity metadata. From the named entities meta-data we extract the list of literals (\"India\") and the beginning index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "named_entities = [(n[3], n[2]) for n in named_entities]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(5, [u'India'])]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "named_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 1, 0, 1, 3, 0, 0, 1, 2, 3, 2]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions with old labels: \n",
      "['SH_upgrade-02', 'SH_fire-01', 'SH_control-01', 'RL_ARG1', 'SH_system', 'RL_ARG0-of', 'DN', 'SH_country', 'SH_tank', 'RL_mod', 'RR_poss', 'DN', 'RR_ARG1']\n",
      "Original Amr\n",
      "(u / upgrade-02~e.0 \n",
      "      :ARG1 (s / system~e.3 \n",
      "            :ARG0-of (c / control-01~e.2 \n",
      "                  :ARG1 (f / fire-01~e.1)) \n",
      "            :poss~e.4 (t / tank~e.6 \n",
      "                  :mod (c2 / country :wiki \"India\" \n",
      "                        :name (n / name :op1 \"India\"~e.5)))))\n",
      "Predicted Amr\n",
      "( d1 / upgrade-02 \n",
      "\t:ARG1  ( d1_1 / system \n",
      "\t\t:ARG0-of  ( d1_1_1 / control-01 \n",
      "\t\t\t:ARG1  ( d1_1_1_1 / fire-01 )\n",
      "\t\t)\n",
      "\t\t:poss  ( d1_1_2 / tank \n",
      "\t\t\t:mod  ( d1_1_2_1 / country \n",
      "\t\t\t\t:wiki \"India\"\n",
      "\t\t\t\t:name  ( d1_1_2_1_1 / name \n",
      "\t\t\t\t\t:op1 \"India\"\n",
      "\t\t\t\t)\n",
      "\t\t\t)\n",
      "\t\t)\n",
      "\t)\n",
      ")\n",
      "Smatch f-score 1.000000\n"
     ]
    }
   ],
   "source": [
    "vocab_acts = support.Vocab.from_list(['SH', 'RL', 'RR', 'DN', 'SW'])\n",
    "action_objects = support.oracle_actions_to_action_index(actions, vocab_acts)\n",
    "action_indices = [a.index for a in action_objects]\n",
    "action_labels = [a.label for a in action_objects]\n",
    "\n",
    "act = asr.ActionConceptTransfer()\n",
    "act.load_from_action_and_label(action_indices, action_labels)\n",
    "pred_label = act.populate_new_actions(predictions[0])\n",
    "print 'Predictions with old labels: '\n",
    "print pred_label\n",
    "predicted_amr_str = asr.reconstruct_all_ne(pred_label, named_entities, [])\n",
    "\n",
    "\n",
    "smatch_results = smatch_util.SmatchAccumulator()\n",
    "original_amr = smatch_amr.AMR.parse_AMR_line(amr_str)\n",
    "predicted_amr = smatch_amr.AMR.parse_AMR_line(predicted_amr_str)\n",
    "smatch_f_score = smatch_results.compute_and_add(predicted_amr, original_amr)\n",
    "\n",
    "print 'Original Amr'\n",
    "print amr_str\n",
    "print 'Predicted Amr'\n",
    "print predicted_amr_str\n",
    "print 'Smatch f-score %f' % smatch_f_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A sentence with Swap. Swap is hard to predict because it appears very rarely in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mappings between node variables and their corresponding concepts.\n",
      "\n",
      "{'f': 'future', 'h': 'have-03', 'm': 'major-02', 'p': 'plan-01', 's': 'scheme', 'r': 'renovate-01', 'w': 'we', 's2': 'seem-01'}\n",
      "\n",
      "Mappings between nodes and all the aligned tokens: If the nodes don't havea variable (polarity, literals, quantities, interrogatives), they specify both the aligned tokens and the parent in order to uniquely identify them\n",
      "\n",
      "{'f': ['5'], 'h': ['8'], 'm': ['13'], 'p': ['15'], 's': ['10'], 'r': ['14'], 'w': ['7'], 's2': ['1']}\n",
      "\n",
      "Mappings between relations and tokens. Uniquely identified by also specifying the parent of that relation.\n",
      "\n",
      "{'ARG1': [[('3', 's2')]]}\n",
      "\n",
      "Mappings from a node to each child, along with the relation between them.\n",
      "\n",
      "Key: f\n",
      "Leaf\n",
      "\n",
      "Key: h\n",
      "ARG0 -> w\n",
      "ARG1 -> s\n",
      "\n",
      "Key: m\n",
      "Leaf\n",
      "\n",
      "Key: p\n",
      "ARG1 -> r\n",
      "ARG1-of -> m\n",
      "\n",
      "Key: s\n",
      "purpose -> f\n",
      "mod -> p\n",
      "\n",
      "Key: r\n",
      "Leaf\n",
      "\n",
      "Key: w\n",
      "Leaf\n",
      "\n",
      "Key: s2\n",
      "ARG1 -> h\n",
      "\n",
      "\n",
      "All the nodes in the amr should appear here.\n",
      "\n",
      "['f', 'h', 'm', 'p', 's', 'r', 'w', 's2']\n",
      "\n",
      "Creating custom AMR.\n",
      "\n",
      "\n",
      "Custom AMR token to concepts dict\n",
      "\n",
      "{1: ('s2', 'seem-01'), 5: ('f', 'future'), 7: ('w', 'we'), 8: ('h', 'have-03'), 10: ('s', 'scheme'), 13: ('m', 'major-02'), 14: ('r', 'renovate-01'), 15: ('p', 'plan-01')}\n",
      "\n",
      "Custom AMR relations dict\n",
      "\n",
      "{('p', 's'): ('mod', ['r', 'm'], ['15']), ('r', 'p'): ('ARG1', [], ['14']), ('s2', ''): ('', ['h'], ['1']), ('f', 's'): ('purpose', [], ['5']), ('h', 's2'): ('ARG1', ['w', 's'], ['8']), ('w', 'h'): ('ARG0', [], ['7']), ('m', 'p'): ('ARG1-of', [], ['13']), ('s', 'h'): ('ARG1', ['f', 'p'], ['10'])}\n",
      "\n",
      "Custom AMR parent dict\n",
      "\n",
      "{'f': 's', 'h': 's2', 'm': 'p', 'p': 's', 's': 'h', 'r': 'p', 'w': 'h', 's2': ''}\n",
      "['DN', 'SH_seem-01_s2', 'DN', 'DN', 'DN', 'SH_future_f', 'DN', 'SH_we_w', 'SH_have-03_h', 'RL_ARG0', 'DN', 'SH_scheme_s', 'DN', 'DN', 'SH_major-02_m', 'SH_renovate-01_r', 'SH_plan-01_p', 'RL_ARG1', 'RL_ARG1-of', 'RR_mod', 'DN', 'SW', 'RL_purpose', 'RR_ARG1', 'RR_ARG1']\n",
      "Model path is:\n",
      "./models/all_epochs=15_maxlen=30_embeddingsdim=300\n",
      "Word index len: \n",
      "7107\n",
      "Test data shape: \n",
      "(1, 17)\n",
      "(1, 25)\n",
      "(1,)\n",
      "1\n",
      "Found 400000 word vectors.\n",
      "Embedding match for volume-quantity\n",
      "Embedding match for distance-quantity\n",
      "Embedding match for energy-quantity\n",
      "Embedding match for power-quantity\n",
      "Embedding match for mass-quantity\n",
      "Embedding match for monetary-quantity\n",
      "Embedding match for temporal-quantity\n",
      "Embedding match for date-entity\n",
      "Not found: ['around~', 'blowjobs', \"don'cha\", 'it...', 'dumbfuck', 'statement/report', '25+', 'booyah', 'railway-line', 'though...', 'decisiohttp://www.historyofwar.org/articles/wars_downfall3.htmln', \"'?\", '\\'\"', \"'.\", 'href=\"http://themamas.org/about-the-madison-area-music-awards/mission-vision-statements/\">', 'miscoding', 'colenel', 'obamabots', '............', '!!!!!!', 'k00', 'http://news.cnet.com/8301-1035_3-57572850-94/doj-lets-important-deadline-pass-in-t-mobile-metropcs-deal/', 'remaning', 'theblaze.com', 'nannystate', 'right..', 'http://www.bradblog.com/?p=7906', \"'s...\", 'political-party', 'lastly..', 'href=\"http://www.youtube.com/watch?v=eqg1hu0pmg0\">', 'href=\"http://www.mideastweb.org/palpop.htm\">', 'class..', '((', 'href=\"http://dictionary.reference.com/browse/charity\">', 'yayn', 'sakeenah', 'href=\"http://www.gwu.edu/~nsarchiv/nsaebb/nsaebb162/index.htm\">', 'href=\"http://www.ndp.ca/platform/healthcare\">', 'one....', 'gimmmeeeee', 'fianlly', 'esrp', 'batshit', '.\\xe2\\x80\\x9d', \"isn't...\", 'crapola', 'audasity', '...where', '****', '2h2', 'yes..', 'hmm...good', 'head~', 'whackjobs', 'mmmk', 'know..', 'rofl', ')\"', 'criminal-organization', '<a', '\"?!?!', 'might~', 'href=\"http://science.nasa.gov/newhome/headlines/essd06oct97_1.htm\">', 'http://www.representativepress.org/israelhistory.html', 'href=\"http://cthealth.server101.com/the_case_for_universal_health_care_in_the_united_states.htm\">', 'goooooood', 'spin..', 'securitynet', 'minutiea', 'libbs', 'ethnic-group', 'worship-place', '<--', 'wedgy', 'resarch', 'evinidence', 'anaonymous', 'imho', '#10', 'natural-object', '=/', 'numpty', 'conservs', '225k', 'though..', 'dumb...', '//www.youtube.com/watch', 'out..', 'grats', '\\xc2\\xa7', 'victims\\xe2\\x84\\xa2.', '3,794,100', 'nutjob', 'times..', 'href=\"http://whatreallyhappened.com/wrharticles/pearl/www.geocities.com/pentagon/6315/fdr.html\">', 'bday', '......', 'dumbass', 'href=\"http://news.cnet.com/8301-1035_3-57572850-94/doj-lets-important-deadline-pass-in-t-mobile-metropcs-deal/\">', 'moonbats', 'them..', 'href=\"http://www.wired.com/wiredscience/2008/03/colbert-and-kam/\">', 'dipshit', '.............', '!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!', 'accusatio', 'funny...', 'href=\"http://nation.foxnews.com/ft-hood-shooting/2011/12/07/obama-regime-calls-ft-hood-shooting-workplace-violence\">', 'occsassionally', 'temperatures.?', 'amusement-park', 'david...', '17189', 'trng', '534446433', 'foresnics', 'href=\"http://visiontoamerica.org/5959/gingrich-i-helped-defeat-communism/\">', 'ignorants', 'href=\"http://www.businessweek.com/articles/2012-03-16/wanted-more-ceos-in-washington\">', '???????????', 'typo--yes', '********************************', 'me......', 'asshat', 'out...', 'indisputible', 'tless', 'href=\"http://www.factcheck.org/2008/01/clinton-passed-on-killing-bin-laden/\">', 'reamain', 'href=\"http://www.sakeenah.org/celebrate.shtml\">', 'slammed..', '-@', '->', 'country-region', 'editec', 'gulty', '@-', '..........', 'nycarbineer', '****ing', 'phear', 'goals=', '****.', 'educated(?)', '*passes', 'http://www.themamas.org/', '\"..', 'indeciperable', 'href=\"http://cnsnews.com/node/464826\">', 'religious-group', 'tatements/', \"'....\", '???????', 'political-movement', 'ok..', '^^case', '</a>', '#name', '.)', '..', '.\"', 'liar..', 'overwhelingly', 'href=\"http://www.snopes.com/rumors/clinton.asp\">', '*******', '.......', 'href=\"http://www.avert.org/aids-history-america.htm\">', 'dosent', '\\xe2\\x80\\x9d.', '\\xe2\\x80\\x9d?', 'attrocious', 'about.?', 'ilogical', 'about..', 'ummmmm', 'a.d.?', 'href=\"http://www.themamas.org/\">', 'afelm', 'cringeworthy', 'taxes..', 'href=\"http://www.counterpunch.org/2011/12/02/debt-slavery-%e2%80%93-why-it-destroyed-rome-why-it-will-destroy-us-unless-it%e2%80%99s-stopped/\">', '**edit**', 'href=\"http://www.britannica.com/ebchecked/topic/89739/caliphate\">', 'bwahahahaaa', 'inacurate', 'negs', 'href=\"http://www.businessinsider.com/cornell-wins-bloombergs-nyc-tech-campus-heres-what-the-2-million-square-foot-school-will-look-like-2011-12\">', ':wink', 'immie', 'historicall', 'pusses', 'broadcast-program', '0.00525', 'negged', 'href=\"http://www.newscientist.com/article/dn14527-climate-myths-global-warming-stopped-in-1998.html\">', 'gunna', 'pussies', 'http://www.mideastweb.org/palpop.htm', 'href=\"http://video.foxnews.com/v/3982487/live-free-or-die\">', 'dear..', 'href=\"http://www.bradblog.com/?p=7906\">', 'oil..', 'href=\"mailto:elrushbo@eibnet.com\">', 'href=\"http://www.plannedparenthood.org/health-center/centerdetails.asp?f=3945&a=90070&v=details\">', 'to..', 'sourcewatch', '...and', 'href=\"http://www.latimes.com/world/worldnow/la-fg-wn-suicide-bomber-pakistan-20130922,0,923285.story\">', 'car-make', 'oohhhhhh', 'local-region', 'blog-01', 'work-of-art', 'href=\"http://www.adl.org/holocaust/weber.asp\">', 'dyspraxia', 'definate', 'innit', 'shoot-02', 'marccy', 'asswipe', 'true..', '??????????', \"rw'er\", 'srsly', '//www.vanityfair.com/commentary/content/articles/050411roco03c', 'indesputable', 'href=\"http://www.law.umkc.edu/faculty/projects/ftrials/conlaw/rightofprivacy.html\">', 'oo0o', '!!???', 'a....well', 'halarious', 'href=\"http://scienceblogs.com/gregladen/2011/03/the_fukushima_disaster_hyperbo.php?utm_source=networkbanner&utm_medium=link\">', 'up..', 'baddy', 'shitstain', 'excusatio', 'governmenht', 'href=\"http://www.democracynow.org/2011/2/15/obamas_37_trillion_budget_calls_for\">', 'christianoid', 'petita', 'lable', 'carrry', '..............', 'sandy..', 'strawmanning', 'country..', 'paulestinian', 'href=\"http://www.usmessageboard.com/4267872-post42.html\">', 'nerly', '!!!!!!!', 'lulz', 'weapon..', 'href=\"http://www.youtube.com/watch?v=nz5amhi9g7o\">', 'blowjob', 'natural-disaster', 'pe4', 'course..', 'so....who', 'href=\"http://en.wikipedia.org/wiki/fallacy\">', '@:@', 'pgpcoder', '.........', 'href=\"http://www.salon.com/news/1998/03/cov_12news.html\">', 'warmist', '970000', 'market-sector', 'happned', 'href=\"http://www.snopes.com/quotes/internet.asp\">', \"won't\", 'excuses..', 'sports-facility', 'fauxtography', 'inherrently', 'prodiction', 'itelf', 'thankies', 'right...', '*no*', 'fuckwhit', 'dufus', 'actaul', \"s'okay\", 'ayup', 'allll', 'href=\"http://www.decisionsonevidence.com/2011/10/do-regulations-curtail-job-growth/\">', '1234567', 'is..', 'not..', 'skaptiks', 'toiba', 'turdboat', 'soon...', 'href=\"http://prospect.org/article/why-we-need-occupy-wall-street?utm_source=daily+digest&utm_campaign=39ed4689d6-dd_11_16_1111_16_2011&utm_medium=email\">', 'rule-01', 'href=\"http://www.theblaze.com/stories/beck-doesnt-hold-back-in-gingrich-interview-tough-questions-on-mandates-big-govt-and-global-warming/\">', 'huuuge', 'href=\"http://cnsnews.com/news/article/half-unemployment-rate-decline-due-people-giving-job-search-labor-data-show\">', 'href=\"http://democratherald.com/news/opinion/editorial/editorial-once-again-fluoridation/article_e82f150c-6263-11e1-aab4-001871e3ce6c.html#ixzz1o0ksmtvn\">', 'href=\"http://www.votersunite.org/info/es&sinthenews.pdf\">', '\"...', 'bwahahahaa', 'ransomware', '~shakes', 'now..', \"havn't\", 'aircraft-type', 'twoofer', '\"~', 'contracption', '\",', '\".', '\"?', 'nutbag', 'regretable', 'slowy', 'world-region', '[/', \"ain't\", '@-@', 'v=iaadvod2srq', 'llocks', 'motherfucking', 'miniture', 'intergency', 'pay..', 'tbh', 'nowhatimean', '?????????????', 'elrushbo@eibnet.com', 'raincloud', '^^^', 'music-key', 'aeroplace', \"y'all\", 'dickhead', '#9', '#8', '#3', '#2', '#1', '#7', '#5', '#4', '@/@', 'said..', 'http://www.votersunite.org/info/es&sinthenews.pdf', 'braniac', 'mehbeh', '303.00', 'ehh', '75+', 'tickee', 'neithe', 'admittted', 'helloo000', '????????', 'point^^', 'href=\"http://members.iinet.net.au/~gduncan/massacres_pacific.html\">', 'href=\"http://mochamanual.com/mochamanual/trying-to-conceive/are-your-fortified-the-facts-about-folic-acid-what-every-black-woman-needs-to-know.html\">', 'obummer', 'oralloy', 'href=\"http://www.digitalhistory.uh.edu/do_history/decisions/hiroshima.html\">', 'cmpanies', 'won\\xe2\\x80\\x99t', 'regional-group', 'htis', 'cannont', 'braawwk', 'crocidolite', 'rediculous', '!!!.....', 'not...it', '25,28,32', 'jail...', 'puhleeze', 'href=\"http://www.usmessageboard.com/attachments/politics/17189-is-the-media-in-the-bag-for-newt-head_up.jpg\">', 'typical...', 'hahahaha', 'scan..', 'crazy..', 'pubication', '8.', 'anyhoo', 'http://themamas.org/about-the-madison-a...', 'wittle', 'lepruchauns', 'braawwkkk', 'stumped..', 'hehehe', 'interviened', 'no\\xe2\\x80\\xa6', 'research-institute', 'city-district', 'href=\"http://www.latimes.com/news/politics/la-pn-obama-clinton-most-admired-gallup-20111227,0,4670281.story\">', 'nucleic-acid', '!!!!!!1', 'qudea', 'zro2', 'government-organization', 'sustainingly', '18701954600', 'case..', 'href=\"http://www.representativepress.org/israelhistory.html\">']\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_19 (InputLayer)            (None, 30)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_20 (InputLayer)            (None, 30)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_21 (InputLayer)            (None, 30)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_22 (InputLayer)            (None, 30)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)          (None, 30, 300)       2132700                                      \n",
      "____________________________________________________________________________________________________\n",
      "input_23 (InputLayer)            (None, 30, 5)         0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_24 (InputLayer)            (None, 30, 6)         0                                            \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)      (None, 30, 1211)      0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                    (None, 30, 1024)      9158656                                      \n",
      "____________________________________________________________________________________________________\n",
      "time_distributed_4 (TimeDistribu (None, 30, 5)         5125                                         \n",
      "====================================================================================================\n",
      "Total params: 11,296,481.0\n",
      "Trainable params: 9,163,781.0\n",
      "Non-trainable params: 2,132,700.0\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_19 (InputLayer)            (None, 30)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_20 (InputLayer)            (None, 30)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_21 (InputLayer)            (None, 30)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_22 (InputLayer)            (None, 30)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)          (None, 30, 300)       2132700                                      \n",
      "____________________________________________________________________________________________________\n",
      "input_23 (InputLayer)            (None, 30, 5)         0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_24 (InputLayer)            (None, 30, 6)         0                                            \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)      (None, 30, 1211)      0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                    (None, 30, 1024)      9158656                                      \n",
      "____________________________________________________________________________________________________\n",
      "time_distributed_4 (TimeDistribu (None, 30, 5)         5125                                         \n",
      "====================================================================================================\n",
      "Total params: 11,296,481.0\n",
      "Trainable params: 9,163,781.0\n",
      "Non-trainable params: 2,132,700.0\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "Buffer and stack at end of prediction\n",
      "[]\n",
      "[14]\n",
      "Sentence\n",
      "it seems that for the future , we have a scheme , a major renovation plan . \n",
      "\n",
      "Predicted\n",
      "SH SH SH DN DN SH RL DN SH SH RL DN SH RL DN DN SH SH RL RL RL SH RL RR DN RR \n",
      "\n",
      "Actual\n",
      "DN SH DN DN DN SH DN SH SH RL DN SH DN DN SH SH SH RL RL RR DN SW RL RR RR \n",
      "\n",
      "Predictions with old labels: \n",
      "['SH_seem-01', 'SH_future', 'SH_we', 'DN', 'DN', 'SH_have-03', 'RL_ARG0', 'DN', 'SH_scheme', 'SH_major-02', 'RL_ARG1', 'DN', 'SH_renovate-01', 'RL_ARG1-of', 'DN', 'DN', 'SH_plan-01', 'SH_unk', 'RL_mod', 'RL_purpose', 'RL_ARG1', 'SH_unk', 'RL_ARG1', 'RR_unk', 'DN', 'RR_unk']\n",
      "Original Amr\n",
      "(s2 / seem-01~e.1\n",
      "       :ARG1~e.3 (h / have-03~e.8\n",
      "             :ARG0 (w / we~e.7)\n",
      "             :ARG1 (s / scheme~e.10\n",
      "                   :mod (p / plan-01~e.15\n",
      "                   :ARG1 (r / renovate-01~e.14)\n",
      "                         :ARG1-of (m / major-02~e.13))\n",
      "                   :purpose (f / future~e.5))))\n",
      "Predicted Amr\n",
      "( d1 / seem-01 \n",
      "\t:unk  ( d1_1 / future \n",
      "\t\t:unk  ( d1_1_1 / unk \n",
      "\t\t\t:ARG1  ( d1_1_1_1 / unk \n",
      "\t\t\t\t:mod  ( d1_1_1_1_1 / plan-01 )\n",
      "\t\t\t\t:purpose  ( d1_1_1_1_2 / renovate-01 \n",
      "\t\t\t\t\t:ARG1-of  ( d1_1_1_1_2_1 / major-02 \n",
      "\t\t\t\t\t\t:ARG1  ( d1_1_1_1_2_1_1 / scheme )\n",
      "\t\t\t\t\t)\n",
      "\t\t\t\t)\n",
      "\t\t\t\t:ARG1  ( d1_1_1_1_3 / have-03 \n",
      "\t\t\t\t\t:ARG0  ( d1_1_1_1_3_1 / we )\n",
      "\t\t\t\t)\n",
      "\t\t\t)\n",
      "\t\t)\n",
      "\t)\n",
      ")\n",
      "Smatch f-score 0.555556\n",
      "1/1 [==============================] - 0s\n"
     ]
    }
   ],
   "source": [
    "amr_str = \"\"\"(s2 / seem-01~e.1\n",
    "       :ARG1~e.3 (h / have-03~e.8\n",
    "             :ARG0 (w / we~e.7)\n",
    "             :ARG1 (s / scheme~e.10\n",
    "                   :mod (p / plan-01~e.15\n",
    "                   :ARG1 (r / renovate-01~e.14)\n",
    "                         :ARG1-of (m / major-02~e.13))\n",
    "                   :purpose (f / future~e.5))))\"\"\"\n",
    "sentence = \"\"\"It seems that for the future , we have a scheme , a major renovation plan .\"\"\"\n",
    "amr = AMR.parse_string(amr_str)\n",
    "custom_amr = generate_custom_amr(amr)\n",
    "actions = generate_action_sequence(custom_amr, sentence)\n",
    "print actions\n",
    "deps = extract_dependencies(sentence)\n",
    "predictions = test(model_name=model2, tokenizer_path=\"./tokenizers/full_tokenizer.dump\",\n",
    "     data=[(sentence, actions, amr_str, deps)], max_len=max_len2, embedding_dim=embeddings_dim2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### We will now test a sentence with a <span style=\"color:red\">date-entity</span> in it. We preprocess the date-entity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "amr_str = \"\"\"(d / difficult~e.5 \n",
    "      :domain~e.4 (r / reach-01~e.7 \n",
    "            :ARG1 (c / consensus~e.0 \n",
    "                  :topic~e.1 (c2 / country :wiki \"India\" \n",
    "                        :name (n / name :op1 \"India\"~e.2))) \n",
    "            :time~e.8 (m / meet-03~e.11 \n",
    "                  :ARG0 (o / organization :wiki \"Nuclear_Suppliers_Group\" \n",
    "                        :name (n2 / name :op1 \"NSG\"~e.10)) \n",
    "                  :time~e.12 (d2 / date-entity :year 2007~e.14 :month~e.13 11~e.13))))\"\"\"\n",
    "sentence = \"\"\"Consensus on India will be difficult to reach when the NSG meets in November 2007 .\"\"\"\n",
    "amr = AMR.parse_string(amr_str)\n",
    "(new_amr, new_sentence, named_entities) = TokensReplacer.replace_named_entities(amr, sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Consensus on country will be difficult to reach when the organization meets in November 2007 .'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('c2', 'n', [u'India'], 2, 2, <amr_util.Node.Node instance at 0x13967e5a8>),\n",
       " ('o', 'n2', [u'NSG'], 10, 10, <amr_util.Node.Node instance at 0x13967e998>)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "named_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(new_amr, new_sentence, date_entities) = TokensReplacer.replace_date_entities(new_amr, new_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Consensus on country will be difficult to reach when the organization meets in date-entity .'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For <span style=\"color:red\">date-entities</span> we store information concerning the concept, quantity pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('d2',\n",
       "  ['11', '2007'],\n",
       "  ['month', 'year'],\n",
       "  13,\n",
       "  14,\n",
       "  <amr_util.Node.Node instance at 0x1389f6518>)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mappings between node variables and their corresponding concepts.\n",
      "\n",
      "{'c': 'consensus', 'd': 'difficult', 'm': 'meet-03', 'o': 'organization', 'r': 'reach-01', 'c2': 'country', 'd2': 'date-entity'}\n",
      "\n",
      "Mappings between nodes and all the aligned tokens: If the nodes don't havea variable (polarity, literals, quantities, interrogatives), they specify both the aligned tokens and the parent in order to uniquely identify them\n",
      "\n",
      "{'c': ['0'], 'd': ['5'], 'm': ['11'], 'o': ['10'], 'r': ['7'], 'c2': ['2'], 'd2': [13]}\n",
      "\n",
      "Mappings between relations and tokens. Uniquely identified by also specifying the parent of that relation.\n",
      "\n",
      "{'topic': [[('1', 'c')]], 'domain': [[('4', 'd')]], 'time': [[('12', 'm')], [('8', 'r')]], 'month': [[('13', 'd2')]]}\n",
      "\n",
      "Mappings from a node to each child, along with the relation between them.\n",
      "\n",
      "Key: c\n",
      "topic -> c2\n",
      "\n",
      "Key: d\n",
      "domain -> r\n",
      "\n",
      "Key: m\n",
      "ARG0 -> o\n",
      "time -> d2\n",
      "\n",
      "Key: o\n",
      "Leaf\n",
      "\n",
      "Key: r\n",
      "ARG1 -> c\n",
      "time -> m\n",
      "\n",
      "Key: c2\n",
      "Leaf\n",
      "\n",
      "Key: d2\n",
      "Leaf\n",
      "\n",
      "\n",
      "All the nodes in the amr should appear here.\n",
      "\n",
      "['c', 'd', 'm', 'o', 'r', 'c2', 'd2']\n",
      "\n",
      "Creating custom AMR.\n",
      "\n",
      "\n",
      "Custom AMR token to concepts dict\n",
      "\n",
      "{0: ('c', 'consensus'), 2: ('c2', 'country'), 5: ('d', 'difficult'), 7: ('r', 'reach-01'), 10: ('o', 'organization'), 11: ('m', 'meet-03'), 13: ('d2', 'date-entity')}\n",
      "\n",
      "Custom AMR relations dict\n",
      "\n",
      "{('o', 'm'): ('ARG0', [], ['10']), ('c', 'r'): ('ARG1', ['c2'], ['0']), ('m', 'r'): ('time', ['o', 'd2'], ['11']), ('r', 'd'): ('domain', ['c', 'm'], ['7']), ('d', ''): ('', ['r'], ['5']), ('c2', 'c'): ('topic', [], ['2']), ('d2', 'm'): ('time', [], [13])}\n",
      "\n",
      "Custom AMR parent dict\n",
      "\n",
      "{'c': 'r', 'd': '', 'm': 'r', 'o': 'm', 'r': 'd', 'c2': 'c', 'd2': 'm'}\n",
      "['SH_consensus_c', 'DN', 'SH_country_c2', 'RR_topic', 'DN', 'DN', 'SH_difficult_d', 'DN', 'SH_reach-01_r', 'DN', 'DN', 'SH_organization_o', 'SH_meet-03_m', 'RL_ARG0', 'DN', 'SH_date-entity_d2', 'RR_time', 'RR_time', 'DN', 'SW', 'RL_ARG1', 'RR_domain']\n"
     ]
    }
   ],
   "source": [
    "custom_amr = generate_custom_amr(new_amr)\n",
    "actions = generate_action_sequence(custom_amr, new_sentence)\n",
    "print actions\n",
    "deps = extract_dependencies(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model path is:\n",
      "./models/all_epochs=15_maxlen=30_embeddingsdim=300\n",
      "Word index len: \n",
      "7107\n",
      "Test data shape: \n",
      "(1, 15)\n",
      "(1, 22)\n",
      "(1,)\n",
      "1\n",
      "Found 400000 word vectors.\n",
      "Embedding match for volume-quantity\n",
      "Embedding match for distance-quantity\n",
      "Embedding match for energy-quantity\n",
      "Embedding match for power-quantity\n",
      "Embedding match for mass-quantity\n",
      "Embedding match for monetary-quantity\n",
      "Embedding match for temporal-quantity\n",
      "Embedding match for date-entity\n",
      "Not found: ['around~', 'blowjobs', \"don'cha\", 'it...', 'dumbfuck', 'statement/report', '25+', 'booyah', 'railway-line', 'though...', 'decisiohttp://www.historyofwar.org/articles/wars_downfall3.htmln', \"'?\", '\\'\"', \"'.\", 'href=\"http://themamas.org/about-the-madison-area-music-awards/mission-vision-statements/\">', 'miscoding', 'colenel', 'obamabots', '............', '!!!!!!', 'k00', 'http://news.cnet.com/8301-1035_3-57572850-94/doj-lets-important-deadline-pass-in-t-mobile-metropcs-deal/', 'remaning', 'theblaze.com', 'nannystate', 'right..', 'http://www.bradblog.com/?p=7906', \"'s...\", 'political-party', 'lastly..', 'href=\"http://www.youtube.com/watch?v=eqg1hu0pmg0\">', 'href=\"http://www.mideastweb.org/palpop.htm\">', 'class..', '((', 'href=\"http://dictionary.reference.com/browse/charity\">', 'yayn', 'sakeenah', 'href=\"http://www.gwu.edu/~nsarchiv/nsaebb/nsaebb162/index.htm\">', 'href=\"http://www.ndp.ca/platform/healthcare\">', 'one....', 'gimmmeeeee', 'fianlly', 'esrp', 'batshit', '.\\xe2\\x80\\x9d', \"isn't...\", 'crapola', 'audasity', '...where', '****', '2h2', 'yes..', 'hmm...good', 'head~', 'whackjobs', 'mmmk', 'know..', 'rofl', ')\"', 'criminal-organization', '<a', '\"?!?!', 'might~', 'href=\"http://science.nasa.gov/newhome/headlines/essd06oct97_1.htm\">', 'http://www.representativepress.org/israelhistory.html', 'href=\"http://cthealth.server101.com/the_case_for_universal_health_care_in_the_united_states.htm\">', 'goooooood', 'spin..', 'securitynet', 'minutiea', 'libbs', 'ethnic-group', 'worship-place', '<--', 'wedgy', 'resarch', 'evinidence', 'anaonymous', 'imho', '#10', 'natural-object', '=/', 'numpty', 'conservs', '225k', 'though..', 'dumb...', '//www.youtube.com/watch', 'out..', 'grats', '\\xc2\\xa7', 'victims\\xe2\\x84\\xa2.', '3,794,100', 'nutjob', 'times..', 'href=\"http://whatreallyhappened.com/wrharticles/pearl/www.geocities.com/pentagon/6315/fdr.html\">', 'bday', '......', 'dumbass', 'href=\"http://news.cnet.com/8301-1035_3-57572850-94/doj-lets-important-deadline-pass-in-t-mobile-metropcs-deal/\">', 'moonbats', 'them..', 'href=\"http://www.wired.com/wiredscience/2008/03/colbert-and-kam/\">', 'dipshit', '.............', '!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!', 'accusatio', 'funny...', 'href=\"http://nation.foxnews.com/ft-hood-shooting/2011/12/07/obama-regime-calls-ft-hood-shooting-workplace-violence\">', 'occsassionally', 'temperatures.?', 'amusement-park', 'david...', '17189', 'trng', '534446433', 'foresnics', 'href=\"http://visiontoamerica.org/5959/gingrich-i-helped-defeat-communism/\">', 'ignorants', 'href=\"http://www.businessweek.com/articles/2012-03-16/wanted-more-ceos-in-washington\">', '???????????', 'typo--yes', '********************************', 'me......', 'asshat', 'out...', 'indisputible', 'tless', 'href=\"http://www.factcheck.org/2008/01/clinton-passed-on-killing-bin-laden/\">', 'reamain', 'href=\"http://www.sakeenah.org/celebrate.shtml\">', 'slammed..', '-@', '->', 'country-region', 'editec', 'gulty', '@-', '..........', 'nycarbineer', '****ing', 'phear', 'goals=', '****.', 'educated(?)', '*passes', 'http://www.themamas.org/', '\"..', 'indeciperable', 'href=\"http://cnsnews.com/node/464826\">', 'religious-group', 'tatements/', \"'....\", '???????', 'political-movement', 'ok..', '^^case', '</a>', '#name', '.)', '..', '.\"', 'liar..', 'overwhelingly', 'href=\"http://www.snopes.com/rumors/clinton.asp\">', '*******', '.......', 'href=\"http://www.avert.org/aids-history-america.htm\">', 'dosent', '\\xe2\\x80\\x9d.', '\\xe2\\x80\\x9d?', 'attrocious', 'about.?', 'ilogical', 'about..', 'ummmmm', 'a.d.?', 'href=\"http://www.themamas.org/\">', 'afelm', 'cringeworthy', 'taxes..', 'href=\"http://www.counterpunch.org/2011/12/02/debt-slavery-%e2%80%93-why-it-destroyed-rome-why-it-will-destroy-us-unless-it%e2%80%99s-stopped/\">', '**edit**', 'href=\"http://www.britannica.com/ebchecked/topic/89739/caliphate\">', 'bwahahahaaa', 'inacurate', 'negs', 'href=\"http://www.businessinsider.com/cornell-wins-bloombergs-nyc-tech-campus-heres-what-the-2-million-square-foot-school-will-look-like-2011-12\">', ':wink', 'immie', 'historicall', 'pusses', 'broadcast-program', '0.00525', 'negged', 'href=\"http://www.newscientist.com/article/dn14527-climate-myths-global-warming-stopped-in-1998.html\">', 'gunna', 'pussies', 'http://www.mideastweb.org/palpop.htm', 'href=\"http://video.foxnews.com/v/3982487/live-free-or-die\">', 'dear..', 'href=\"http://www.bradblog.com/?p=7906\">', 'oil..', 'href=\"mailto:elrushbo@eibnet.com\">', 'href=\"http://www.plannedparenthood.org/health-center/centerdetails.asp?f=3945&a=90070&v=details\">', 'to..', 'sourcewatch', '...and', 'href=\"http://www.latimes.com/world/worldnow/la-fg-wn-suicide-bomber-pakistan-20130922,0,923285.story\">', 'car-make', 'oohhhhhh', 'local-region', 'blog-01', 'work-of-art', 'href=\"http://www.adl.org/holocaust/weber.asp\">', 'dyspraxia', 'definate', 'innit', 'shoot-02', 'marccy', 'asswipe', 'true..', '??????????', \"rw'er\", 'srsly', '//www.vanityfair.com/commentary/content/articles/050411roco03c', 'indesputable', 'href=\"http://www.law.umkc.edu/faculty/projects/ftrials/conlaw/rightofprivacy.html\">', 'oo0o', '!!???', 'a....well', 'halarious', 'href=\"http://scienceblogs.com/gregladen/2011/03/the_fukushima_disaster_hyperbo.php?utm_source=networkbanner&utm_medium=link\">', 'up..', 'baddy', 'shitstain', 'excusatio', 'governmenht', 'href=\"http://www.democracynow.org/2011/2/15/obamas_37_trillion_budget_calls_for\">', 'christianoid', 'petita', 'lable', 'carrry', '..............', 'sandy..', 'strawmanning', 'country..', 'paulestinian', 'href=\"http://www.usmessageboard.com/4267872-post42.html\">', 'nerly', '!!!!!!!', 'lulz', 'weapon..', 'href=\"http://www.youtube.com/watch?v=nz5amhi9g7o\">', 'blowjob', 'natural-disaster', 'pe4', 'course..', 'so....who', 'href=\"http://en.wikipedia.org/wiki/fallacy\">', '@:@', 'pgpcoder', '.........', 'href=\"http://www.salon.com/news/1998/03/cov_12news.html\">', 'warmist', '970000', 'market-sector', 'happned', 'href=\"http://www.snopes.com/quotes/internet.asp\">', \"won't\", 'excuses..', 'sports-facility', 'fauxtography', 'inherrently', 'prodiction', 'itelf', 'thankies', 'right...', '*no*', 'fuckwhit', 'dufus', 'actaul', \"s'okay\", 'ayup', 'allll', 'href=\"http://www.decisionsonevidence.com/2011/10/do-regulations-curtail-job-growth/\">', '1234567', 'is..', 'not..', 'skaptiks', 'toiba', 'turdboat', 'soon...', 'href=\"http://prospect.org/article/why-we-need-occupy-wall-street?utm_source=daily+digest&utm_campaign=39ed4689d6-dd_11_16_1111_16_2011&utm_medium=email\">', 'rule-01', 'href=\"http://www.theblaze.com/stories/beck-doesnt-hold-back-in-gingrich-interview-tough-questions-on-mandates-big-govt-and-global-warming/\">', 'huuuge', 'href=\"http://cnsnews.com/news/article/half-unemployment-rate-decline-due-people-giving-job-search-labor-data-show\">', 'href=\"http://democratherald.com/news/opinion/editorial/editorial-once-again-fluoridation/article_e82f150c-6263-11e1-aab4-001871e3ce6c.html#ixzz1o0ksmtvn\">', 'href=\"http://www.votersunite.org/info/es&sinthenews.pdf\">', '\"...', 'bwahahahaa', 'ransomware', '~shakes', 'now..', \"havn't\", 'aircraft-type', 'twoofer', '\"~', 'contracption', '\",', '\".', '\"?', 'nutbag', 'regretable', 'slowy', 'world-region', '[/', \"ain't\", '@-@', 'v=iaadvod2srq', 'llocks', 'motherfucking', 'miniture', 'intergency', 'pay..', 'tbh', 'nowhatimean', '?????????????', 'elrushbo@eibnet.com', 'raincloud', '^^^', 'music-key', 'aeroplace', \"y'all\", 'dickhead', '#9', '#8', '#3', '#2', '#1', '#7', '#5', '#4', '@/@', 'said..', 'http://www.votersunite.org/info/es&sinthenews.pdf', 'braniac', 'mehbeh', '303.00', 'ehh', '75+', 'tickee', 'neithe', 'admittted', 'helloo000', '????????', 'point^^', 'href=\"http://members.iinet.net.au/~gduncan/massacres_pacific.html\">', 'href=\"http://mochamanual.com/mochamanual/trying-to-conceive/are-your-fortified-the-facts-about-folic-acid-what-every-black-woman-needs-to-know.html\">', 'obummer', 'oralloy', 'href=\"http://www.digitalhistory.uh.edu/do_history/decisions/hiroshima.html\">', 'cmpanies', 'won\\xe2\\x80\\x99t', 'regional-group', 'htis', 'cannont', 'braawwk', 'crocidolite', 'rediculous', '!!!.....', 'not...it', '25,28,32', 'jail...', 'puhleeze', 'href=\"http://www.usmessageboard.com/attachments/politics/17189-is-the-media-in-the-bag-for-newt-head_up.jpg\">', 'typical...', 'hahahaha', 'scan..', 'crazy..', 'pubication', '8.', 'anyhoo', 'http://themamas.org/about-the-madison-a...', 'wittle', 'lepruchauns', 'braawwkkk', 'stumped..', 'hehehe', 'interviened', 'no\\xe2\\x80\\xa6', 'research-institute', 'city-district', 'href=\"http://www.latimes.com/news/politics/la-pn-obama-clinton-most-admired-gallup-20111227,0,4670281.story\">', 'nucleic-acid', '!!!!!!1', 'qudea', 'zro2', 'government-organization', 'sustainingly', '18701954600', 'case..', 'href=\"http://www.representativepress.org/israelhistory.html\">']\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_25 (InputLayer)            (None, 30)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_26 (InputLayer)            (None, 30)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_27 (InputLayer)            (None, 30)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_28 (InputLayer)            (None, 30)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)          (None, 30, 300)       2132700                                      \n",
      "____________________________________________________________________________________________________\n",
      "input_29 (InputLayer)            (None, 30, 5)         0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_30 (InputLayer)            (None, 30, 6)         0                                            \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)      (None, 30, 1211)      0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lstm_5 (LSTM)                    (None, 30, 1024)      9158656                                      \n",
      "____________________________________________________________________________________________________\n",
      "time_distributed_5 (TimeDistribu (None, 30, 5)         5125                                         \n",
      "====================================================================================================\n",
      "Total params: 11,296,481.0\n",
      "Trainable params: 9,163,781.0\n",
      "Non-trainable params: 2,132,700.0\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_25 (InputLayer)            (None, 30)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_26 (InputLayer)            (None, 30)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_27 (InputLayer)            (None, 30)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_28 (InputLayer)            (None, 30)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)          (None, 30, 300)       2132700                                      \n",
      "____________________________________________________________________________________________________\n",
      "input_29 (InputLayer)            (None, 30, 5)         0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_30 (InputLayer)            (None, 30, 6)         0                                            \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)      (None, 30, 1211)      0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lstm_5 (LSTM)                    (None, 30, 1024)      9158656                                      \n",
      "____________________________________________________________________________________________________\n",
      "time_distributed_5 (TimeDistribu (None, 30, 5)         5125                                         \n",
      "====================================================================================================\n",
      "Total params: 11,296,481.0\n",
      "Trainable params: 9,163,781.0\n",
      "Non-trainable params: 2,132,700.0\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "Buffer and stack at end of prediction\n",
      "[]\n",
      "[2480]\n",
      "Sentence\n",
      "consensus on country will be difficult to reach when the organization meets in date-entity . \n",
      "\n",
      "Predicted\n",
      "SH DN SH DN DN SH RL DN DN SH DN SH SH RL RL RR DN SH RR DN RR \n",
      "\n",
      "Actual\n",
      "SH DN SH RR DN DN SH DN SH DN DN SH SH RL DN SH RR RR DN SW RL RR \n",
      "\n",
      "Predictions with old labels: \n",
      "['SH_consensus', 'DN', 'SH_country', 'DN', 'DN', 'SH_difficult', 'RL_topic', 'DN', 'DN', 'SH_reach-01', 'DN', 'SH_organization', 'SH_meet-03', 'RL_ARG0', 'RL_time', 'RR_time', 'DN', 'SH_date-entity', 'RR_ARG1', 'DN', 'RR_domain']\n",
      "Original Amr\n",
      "(d / difficult~e.5 \n",
      "      :domain~e.4 (r / reach-01~e.7 \n",
      "            :ARG1 (c / consensus~e.0 \n",
      "                  :topic~e.1 (c2 / country :wiki \"India\" \n",
      "                        :name (n / name :op1 \"India\"~e.2))) \n",
      "            :time~e.8 (m / meet-03~e.11 \n",
      "                  :ARG0 (o / organization :wiki \"Nuclear_Suppliers_Group\" \n",
      "                        :name (n2 / name :op1 \"NSG\"~e.10)) \n",
      "                  :time~e.12 (d2 / date-entity :year 2007~e.14 :month~e.13 11~e.13))))\n",
      "Predicted Amr\n",
      "( d1 / consensus \n",
      "\t:domain  ( d1_1 / difficult \n",
      "\t\t:topic  ( d1_1_1 / country )\n",
      "\t\t:time  ( d1_1_2 / meet-03 \n",
      "\t\t\t:ARG0  ( d1_1_2_1 / organization )\n",
      "\t\t\t:time  ( d1_1_2_2 / reach-01 )\n",
      "\t\t)\n",
      "\t\t:ARG1  ( d1_1_3 / date-entity )\n",
      "\t)\n",
      ")\n",
      "Smatch f-score 0.421053\n",
      "1/1 [==============================] - 0s\n"
     ]
    }
   ],
   "source": [
    "predictions = test(model_name=model2, tokenizer_path=\"./tokenizers/full_tokenizer.dump\",\n",
    "     data=[(new_sentence, actions, amr_str, deps)], max_len=max_len2, embedding_dim=embeddings_dim2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "named_entities = [(n[3], n[2]) for n in named_entities]\n",
    "date_entities = [(d[3], d[2], d[1]) for d in date_entities]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(13, ['month', 'year'], ['11', '2007'])]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions with old labels: \n",
      "['SH_consensus', 'DN', 'SH_country', 'DN', 'DN', 'SH_difficult', 'RL_topic', 'DN', 'DN', 'SH_reach-01', 'DN', 'SH_organization', 'SH_meet-03', 'RL_ARG0', 'RL_time', 'RR_time', 'DN', 'SH_date-entity', 'RR_ARG1', 'DN', 'RR_domain']\n",
      "Original Amr\n",
      "(d / difficult~e.5 \n",
      "      :domain~e.4 (r / reach-01~e.7 \n",
      "            :ARG1 (c / consensus~e.0 \n",
      "                  :topic~e.1 (c2 / country :wiki \"India\" \n",
      "                        :name (n / name :op1 \"India\"~e.2))) \n",
      "            :time~e.8 (m / meet-03~e.11 \n",
      "                  :ARG0 (o / organization :wiki \"Nuclear_Suppliers_Group\" \n",
      "                        :name (n2 / name :op1 \"NSG\"~e.10)) \n",
      "                  :time~e.12 (d2 / date-entity :year 2007~e.14 :month~e.13 11~e.13))))\n",
      "Predicted Amr\n",
      "( d1 / consensus \n",
      "\t:domain  ( d1_1 / difficult \n",
      "\t\t:topic  ( d1_1_1 / country \n",
      "\t\t\t:wiki \"India\"\n",
      "\t\t\t:name  ( d1_1_1_1 / name \n",
      "\t\t\t\t:op1 \"India\"\n",
      "\t\t\t)\n",
      "\t\t)\n",
      "\t\t:time  ( d1_1_2 / meet-03 \n",
      "\t\t\t:ARG0  ( d1_1_2_1 / organization \n",
      "\t\t\t\t:wiki \"NSG\"\n",
      "\t\t\t\t:name  ( d1_1_2_1_1 / name \n",
      "\t\t\t\t\t:op1 \"NSG\"\n",
      "\t\t\t\t)\n",
      "\t\t\t)\n",
      "\t\t\t:time  ( d1_1_2_2 / reach-01 )\n",
      "\t\t)\n",
      "\t\t:ARG1  ( d1_1_3 / date-entity \n",
      "\t\t\t:month \"11\"\n",
      "\t\t\t:year \"2007\"\n",
      "\t\t)\n",
      "\t)\n",
      ")\n",
      "Smatch f-score 0.708333\n"
     ]
    }
   ],
   "source": [
    "vocab_acts = support.Vocab.from_list(['SH', 'RL', 'RR', 'DN', 'SW'])\n",
    "action_objects = support.oracle_actions_to_action_index(actions, vocab_acts)\n",
    "action_indices = [a.index for a in action_objects]\n",
    "action_labels = [a.label for a in action_objects]\n",
    "\n",
    "act = asr.ActionConceptTransfer()\n",
    "act.load_from_action_and_label(action_indices, action_labels)\n",
    "pred_label = act.populate_new_actions(predictions[0])\n",
    "print 'Predictions with old labels: '\n",
    "print pred_label\n",
    "predicted_amr_str = asr.reconstruct_all_ne(pred_label, named_entities, date_entities)\n",
    "\n",
    "\n",
    "smatch_results = smatch_util.SmatchAccumulator()\n",
    "original_amr = smatch_amr.AMR.parse_AMR_line(amr_str)\n",
    "predicted_amr = smatch_amr.AMR.parse_AMR_line(predicted_amr_str)\n",
    "smatch_f_score = smatch_results.compute_and_add(predicted_amr, original_amr)\n",
    "\n",
    "print 'Original Amr'\n",
    "print amr_str\n",
    "print 'Predicted Amr'\n",
    "print predicted_amr_str\n",
    "print 'Smatch f-score %f' % smatch_f_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
